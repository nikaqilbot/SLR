Title,Abstract,Year,PDF Link,Authors,Source,Relevant
A Conceptual Model of ICT-Supported Unified Process of International Outsourcing of Software Production,"This is an ongoing research in international outsourcing software production. This research examines how Software production through the ICTsupported unified process of international outsourcing could be executed and managed effectively. To address this research question, the results of an in-depth literature review in the areas of outsourcing, international outsourcing, information technology, and international software production is presented. This study proposes the information communication technologies' (ICT) - supported unified process model of international outsourcing of software production (SUPMIOSP). ICT-SUPMIOSP provides a detailed guideline on how to manage the entire process of international outsourcing by integrating a number of key issues such as relationship and risks management. Both theoretical and practical aspects of ICTSUPMIOSP are presented. At the theoretical level, the model can be used as a basis for further research, while at the practical level, it helps managers and other stakeholders to understand the multiple activities involved in offshore outsourcing, improve, systematize, and execute the ICT-SUPIOSP more effectively and efficiently.",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4031306,Anicet Yalaho,"EDOCW '06: Proceedings of the 10th IEEE on International Enterprise Distributed Object Computing Conference Workshops , October 2006, Publisher: IEEE Computer Society",1
A Quantitative Assessment of Requirements Engineering Publications ? 1963?2006,"<p>Requirements engineering research has been conducted for over 40 years. It is important to recognize the plethora of results accumulated to date to: (a) improve researchers' understanding of the historical roots of our field in the real-world and the problems that they are trying to solve, (b) expose researchers to the breadth and depth of solutions that have been proposed, (c) provide a synergistic basis for improving those solutions or building new ones to solve real-world problems facing the industry today, and d) increase practitioner awareness of available solutions. A detailed meta-analysis of the requirements engineering literature will provide an objective overview of the advances and current state of the discipline. This paper represents the first step in a planned multi-year analysis. It presents the results of a demographic analysis by date, type, outlet, author, and author affiliation for an existing database of over 4,000 requirements engineering publications.</p>",2007,http://dl.acm.org/citation.cfm?id=1768914&CFID=932216837&CFTOKEN=18963453,"Alan Davis  , Ann Hickey  , Oscar Dieste  , Natalia Juristo   and Ana Moreno","Book Series Lecture Notes in Computer Science, Volume 4542/2007, Book Requirements Engineering: Foundation for Software Quality, Pages 129-143, SpringerLink Date Thursday, June 28, 2007",1
A survey and taxonomy of approaches for mining software repositories in the context of software evolution,"<p>A comprehensive literature survey on approaches for mining software repositories (MSR) in the context of software evolution is presented. In particular, this survey deals with those investigations that examine multiple versions of software artifacts or other temporal information. A taxonomy is derived from the analysis of this literature and presents the work via four dimensions: the type of software repositories mined (what), the purpose (why), the adopted/invented methodology used (how), and the evaluation method (quality). The taxonomy is demonstrated to be expressive (i.e., capable of representing a wide spectrum of MSR investigations) and effective (i.e., facilitates similarities and comparisons of MSR investigations). Lastly, a number of open research issues in MSR that require further investigation are identified.</p>",2007,http://dl.acm.org/citation.cfm?id=1345057&CFID=932209910&CFTOKEN=86972045,"Huzefa Kagdi, Michael L. Collard, Jonathan I. Maletic","Journal of Software Maintenance and Evolution: Research and Practice,   Volume 19 Issue 2, March 2007, Publisher: John Wiley & Sons, Inc.",1
An analysis of data sets used to train and validate cost prediction systems,"OBJECTIVE - to build up a picture of the nature and type of data sets being used to develop and evaluate different software project effort prediction systems. We believe this to be important since there is a growing body of published work that seeks to assess different prediction approaches.METHOD - we performed an exhaustive search from 1980 onwards from three software engineering journals for research papers that used project data sets to compare cost prediction systems.RESULTS - this identified a total of 50 papers that used, one or more times, a total of 71 unique project data sets. We observed that some of the better known and easily accessible data sets were used repeatedly making them potentially disproportionately influential. Such data sets also tend to be amongst the oldest with potential problems of obsolescence. We also note that only about 60% of all data sets are in the public domain. Finally, extracting relevant information from research papers has been time consuming due to different styles of presentation and levels of contextural information.CONCLUSIONS - first, the community needs to consider the quality and appropriateness of the data set being utilised; not all data sets are equal. Second, we need to assess the way results are presented in order to facilitate meta-analysis and whether a standard protocol would be appropriate.",2005,http://dl.acm.org/citation.cfm?id=1083166&CFID=932222344&CFTOKEN=20329875,"Carolyn Mair, Martin Shepperd, Magne J?rgensen","PROMISE '05: Proceedings of the 2005 workshop on Predictor models in software engineering, May 2005",1
Challenges in Collaborative Modeling: A Literature Review,"Modeling is a key activity in conceptual design and system design. Users as well as stakeholders, experts and entrepreneurs need to be able to create shared understanding about a system representation. In this paper we conducted a literature review to provide an overview of studies in which collaborative modeling efforts have been conducted to give first insights in the challenges of collaborative modeling, specifically with respect to group composition, collaboration & participation methods, modeling methods and quality in collaborative modeling. We found a critical challenge in dealing with the lack of modeling skills, such as having a modeler to support the group, or create the model for the group versus training to empower participants to actively participate in the modeling effort, and another critical challenge in resolving conflicting (parts of) models and integration of submodels or models from different perspectives. The overview of challenges presented in this paper will inspire the design of methods and support systems that will ultimately advance the efficiency and effectiveness of collaborative modeling tasks.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6846871,"Michiel Renger, Gwendolyn L. Kolfschoten   and Gert-Jan de Vreede","Book Series Lecture Notes in Business Information Processing, Volume 10, Book Advances in Enterprise Engineering I, Pages 61-77, SpringerLink Date Tuesday, June 10, 2008",1
Controversy Corner: A new research agenda for tool integration,"This article highlights tool integration within software engineering environments. Tool integration concerns the techniques used to form coalitions of tools that provide an environment supporting some, or all, activities within a software engineering process. These techniques have been used to create environments that attempt to address aspects of software development, with varying success. This article provides a timely analysis and review of many of the significant projects in the field and, combined with evidence collected from industry, concludes by proposing an empirical manifesto for future research, where we see the need for work to justify tool integration efforts in terms of relevant socio-economic indicators.",2007,http://dl.acm.org/citation.cfm?id=1282981&CFID=932224415&CFTOKEN=87204745,"M. N. Wicks, R. G. Dewar","Journal of Systems and Software,   Volume 80 Issue 9 , September 2007 , Publisher: Elsevier Science Inc.",1
Data sets and data quality in software engineering,"OBJECTIVE - to assess the extent and types of techniques used to manage quality within software engineering data sets. We consider this a particularly interesting question in the context of initiatives to promote sharing and secondary analysis of data sets. METHOD - we perform a systematic review of available empirical software engineering studies. RESULTS - only 23 out of the many hundreds of studies assessed, explicitly considered data quality. CONCLUSIONS - first, the community needs to consider the quality and appropriateness of the data set being utilised; not all data sets are equal. Second, we need more research into means of identifying, and ideally repairing, noisy cases. Third, it should become routine to use sensitivity analysis to assess conclusion stability with respect to the assumptions that must be made concerning noise levels.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541819,"Gernot A. Liebchen, Martin Shepperd","PROMISE '08: Proceedings of the 4th international workshop on Predictor models in software engineering, May 2008 , Publisher: ACM",1
Developing Open Source Software: A Community-Based Analysis of Research,"Open source software (OSS) creates the potential for the inclusion of large and diverse communities in every aspect of the software development and consumption life cycle. However, despite 6 years of effort by an ever growing research community, we still don’t know exactly what we do and don’t know about OSS, nor do we have a clear idea about the basis for our knowledge. This paper presents an analysis of 155 research artefacts in the area of open source software. The purpose of the study is to identify the kinds of open source project communities that have been researched, the kinds of research questions that have been asked, and the methodologies used by researchers. Emerging from the study is a clearer understanding of what we do and don’t know about open source software, and recommendations for future research efforts ",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7449480,"Joseph Feller, Patrick Finnegan, David Kelly and Maurice MacNamara","Book Series IFIP International Federation for Information Processing, Volume 208/2006, Book Social Inclusion: Societal and Organizational Implications for Information Systems, Pages 261-278, SpringerLink Date Wednesday, September 13, 2006",1
Effectiveness of Requirements Elicitation Techniques: Empirical Results Derived from a Systematic Review,"This paper reports a systematic review of empirical studies concerning the effectiveness of elicitation techniques, and the subsequent aggregation of empirical evidence gathered from those studies. The most significant results of the aggregation process are as follows: (I) interviews, preferentially structured, appear to be one of the most effective elicitation techniques; (2) many techniques often cited in the literature, like card sorting, ranking or thinking aloud, tend to be less effective than interviews; (3) analyst experience does not appear to be a relevant factor; and (4) the studies conducted have not found the use of intermediate representations during elicitation to have significant positive effects. It should be noted that, as a general rule, the studies from which these results were aggregated have not been replicated, and therefore the above claims cannot be said to be absolutely certain. However, they can be used by researchers as pieces of knowledge to be further investigated and by practitioners in development projects, always taking into account that they are preliminary findings",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1704061,"By Alan Davis , Oscar Dieste , Ann Hickey , Natalia Juristo , Ana M. Moreno","Found in: 14th IEEE International Requirements Engineering Conference (RE'06)
Issue Date:September 2006 , pp. 179-188",1
Evidence-Based Guidelines for Assessment of Software Development Cost Uncertainty,"Several studies suggest that uncertainty assessments of software development costs are strongly biased toward overconfidence, i.e., that software cost estimates typically are believed to be more accurate than they really are. This overconfidence may lead to poor project planning. As a means of improving cost uncertainty assessments, we provide evidence-based guidelines for how to assess software development cost uncertainty, based on results from relevant empirical studies. The general guidelines provided are: 1) Do not rely solely on unaided, intuition-based uncertainty assessment processes, 2) do not replace expert judgment with formal uncertainty assessment models, 3) apply structured and explicit judgment-based processes, 4) apply strategies based on an outside view of the project, 5) combine uncertainty assessments from different sources through group work, not through mechanical combination, 6) use motivational mechanisms with care and only if greater effort is likely to lead to improved assessments, and 7) frame the assessment problem to fit the structure of the relevant uncertainty information and the assessment process. These guidelines are preliminary and should be updated in response to new evidence.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1556553,By Magne Jorgensen,"Found in: IEEE Transactions on Software Engineering 
Issue Date:November 2005 , pp. 942-954",1
Experimental context classification: incentives and experience of subjects,"There is a need to identify factors that affect the result of empirical studies in software engineering research. It is still the case that seemingly identical replications of controlled experiments result in different conclusions due to the fact that all factors describing the experiment context are not clearly defined and hence controlled. In this article, a scheme for describing the participants of controlled experiments is proposed and evaluated. It consists of two main factors, the incentives for participants in the experiment and the experience of the participants. The scheme has been evaluated by classifying a set of previously conducted experiments from literature. It can be concluded that the scheme was easy to use and understand. It is also found that experiments that are classified in the same way to a large extent point at the same results, which indicates that the scheme addresses relevant factors.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1553590,"Martin H?st, Claes Wohlin, Thomas Thelin","ICSE '05: Proceedings of the 27th international conference on Software engineering, May 2005, Publisher: ACM",1
How Does a Measurement Programme Evolve in Software Organizations?,"<p><p>Establishing a software measurement programme within an organization is not a straightforward task. Previous literature surveys have focused on software process improvement in general and software measurement has been analysed in case studies. This literature survey collects the data from separate cases and presents the critical success factors that are specific to software measurement programmes. We present a categorization of the success factors based on organizational roles that are involved in measurement. Furthermore, the most essential elements of success in different phases of the life cycle of the measurement programme are analysed. It seems that the role of upper management is crucial when starting measurement and the individual developers' impact increases in the later phases. Utilization of the measurement data and improvement of the measurement and development processes requires active management support again.</p></p>",2008,http://dl.acm.org/citation.cfm?id=1425920&CFID=932207713&CFTOKEN=72281918,"Lasse Harjumaa, Jouni Markkula and Markku Oivo","Book Series Lecture Notes in Computer Science, Volume 5089/2008, Book Product-Focused Software Process Improvement, Pages 230-243, SpringerLink Date Tuesday, June 17, 2008",1
Improving Evidence about Software Technologies: A Look at Model-Based Testing,"Model-based testing (MBT) approaches help automatically generate test cases using models extracted from software artifacts, and hold the promise to greatly affect how we build software. A review of the literature shows that certain specialized domains are applying MBT, but it does not yet seem to be a mainstream approach. The authors therefore conducted a systematic review of the literature to investigate how much evidence is available on MBT's costs and benefits, especially regarding how these techniques compare to other common testing approaches. They use these results to derive suggestions regarding what types of studies might further increase the deployment of these techniques. ",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4497754,"By Arilo Dias Neto , Rajesh Subramanyan , Marlon Vieira , Guilherme Horta Travassos , Forrest Shul","Found in: IEEE Software l 
Issue Date:May 2008 , pp. 10-13",1
In search of `architectural knowledge',"The software architecture community puts more and more emphasis on 'architectural knowledge'. However, there appears to be no commonly accepted definition of what architectural knowledge entails, which makes it a fuzzy concept. In order to obtain a better understanding of how different authors view 'architectural knowledge', we have conducted a systematic review to examine how architectural knowledge is defined and how the different definitions in use are related. From this review it became clear that many authors do not provide a concrete definition of what they think architectural knowledge entails. What is more intriguing, though, is that those who do give a definition seem to agree that architectural knowledge spans from problem domain through decision making to solution; an agreement that is not obvious from the definitions themselves, but which is only brought to light after careful systematic comparison of the different studies.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5659173,"Remco C. de Boer, Rik Farenhorst","SHARK '08: Proceedings of the 3rd international workshop on Sharing and reusing architectural knowledge, May 2008 , Publisher: ACM",1
Measurement in software engineering: From the roadmap to the crossroads.,"Research on software measurement can be organized around five key conceptual and methodological issues: how to apply measurement theory to software, how to frame software metrics, how to develop metrics, how to collect core measures, and how to analyze measures. The subject is of special concern for the industry, which is interested in improving practices - mainly in developing countries, where the software industry represents an opportunity for growth and usually receives institutional support for matching international quality standards. Academics are also in need of understanding and developing more effective methods for managing the software process and assessing the success of products and services, as a result of an enhanced awareness about the emergency of aligning business processes and information systems. This paper unveils the fundamentals of measurement in software engineering and discusses current issues and foreseeable trends for the subject. A literature review was performed within major academic publications in the last decade, and findings suggest a sensible shift of measurement interests towards managing the software process as a whole - without losing from sight the customary focus on hard issues like algorithm efficiency and worker productivity",1997,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=585509,"C. G. P. Bellini, R. D. D. Pereira, and J. L. Becker.","International Journal of Software Engineering and Knowledge Engineering 18 (1):37-64, 2008.",1
Mobile Systems Development: A Literature Review,"This article reviews 105 representative contributions to the literature on mobile systems development. The contributions are categorized according to a simple conceptual framework. The framework comprises four perspectives: the requirements perspective, the technology perspective, the application perspective, and the business perspective. Our literature review shows that mobile systems development is overlooked in the current debate. From the review, we extend the traditional view on systems development to encompass mobile systems and, based on the identified perspectives, we propose core characteristics for mobile systems. We also extend the traditional focus found in systems development on processes in a development project to encompass the whole of the development company as well as interorganizational linkage between development companies. Finally, we point at research directions emerging from the review that are relevant to the field of mobile systems development.",1989,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=198939,Jens Henrik Hosbond and Peter Axel Nielsen,"Book Series IFIP International Federation for Information Processing, Volume 185/2005, Book Designing Ubiquitous Information Environments: Socio-Technical Issues and Challenges, Pages 215-232, SpringerLink Date Thursday, February 09, 2006",1
"Quality, productivity and economic benefits of software reuse: a review of industrial studies","<p>Systematic software reuse is proposed to increase productivity and software quality and lead to economic benefits. Reports of successful software reuse programs in industry have been published. However, there has been little effort to organize the evidence systematically and appraise it. This review aims to assess the effects of software reuse in industrial contexts. Journals and major conferences between 1994 and 2005 were searched to find observational studies and experiments conducted in industry, returning eleven papers of observational type. Systematic software reuse is significantly related to lower problem (defect, fault or error) density in five studies and to decreased effort spent on correcting problems in three studies. The review found evidence for significant gains in apparent productivity in three studies. Other significant benefits of software reuse were reported in single studies or the results were inconsistent. Evidence from industry is sparse and combining results was done by vote-counting. Researchers should pay more attention to using comparable metrics, performing longitudinal studies, and explaining the results and impact on industry. For industry, evaluating reuse of COTS or OSS components, integrating reuse activities in software processes, better data collection and evaluating return on investment are major challenges.</p>",2007,http://dl.acm.org/citation.cfm?id=1290919&CFID=932217338&CFTOKEN=19657119,"Parastoo Mohagheghi, Reidar Conradi","Empirical Software Engineering,   Volume 12 Issue 5, October 2007, Empirical Software Engineering,   Volume 12 Issue 5, October 2007, Publisher: Kluwer Academic Publishers",1
Reflections on 10 Years of Software Process Simulation Modeling,"Software process simulation modeling (SPSM) has become an increasingly active research area since its introduction in the late 1980s. Particularly during the last ten years the related research community and the number of publications have been growing. The objective of this research is to provide insights about the evolution of SPSM research during the last 10 years. A systematic literature review was proposed with two subsequent stages to achieve this goal. This paper presents the preliminary results of the first stage of the review that is exclusively focusing on a core set of publication sources. More than 200 relevant publications were analyzed in order to find answers to the research questions, including the purposes and scopes of SPSM, application domains, and predominant research issues. From the analysis the following conclusions could be drawn: (1) Categories for classifying software process simulation models as suggested by the authors of a landmark publication in 1999 should be adjusted and refined to better capture the diversity of published models. (2) Research improving the efficiency of SPSM is gaining importance. (3) Hybrid process simulation models have attracted interest as a possibility to more realistically capture complex real-world software processes. ",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6984090,"He Zhang, Barbara Kitchenham and Dietmar Pfahl","Book Series Lecture Notes in Computer Science, Volume 5007/2008, Book Making Globally Distributed Software Development a Success Story, Pages 345-356, SpringerLink Date Tuesday, May 06, 2008",1
Software process improvement in small and medium software enterprises: a systematic review,"Small and medium enterprises are a very important cog in the gears of the world economy. The software industry in most countries is composed of an industrial scheme that is made up mainly of small and medium software enterprises--SMEs. To strengthen these types of organizations, efficient Software Engineering practices are needed--practices which have been adapted to their size and type of business. Over the last two decades, the Software Engineering community has expressed special interest in software process improvement (SPI) in an effort to increase software product quality, as well as the productivity of software development. However, there is a widespread tendency to make a point of stressing that the success of SPI is only possible for large companies. In this article, a systematic review of published case studies on the SPI efforts carried out in SMEs is presented. Its objective is to analyse the existing approaches towards SPI which focus on SMEs and which report a case study carried out in industry. A further objective is that of discussing the significant issues related to this area of knowledge, and to provide an up-to-date state of the art, from which innovative research activities can be thought of and planned.",2011,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6083172,"Francisco J. Pino, F?lix Garc?a, Mario Piattini","Software Quality Control,   Volume 16 Issue 2, June 2008, Publisher: Kluwer Academic Publishers, pp 237 - 261",1
Software project economics: a roadmap,"The objective of this paper is to consider research progress in the field of software project economics with a view to identifying important challenges and promising research directions. I argue that this is an important sub-discipline since this will underpin any cost-benefit analysis used to justify the resourcing, or otherwise, of a software project. To accomplish this I conducted a bibliometric analysis of peer reviewed research articles to identify major areas of activity. My results indicate that the primary goal of more accurate cost prediction systems remains largely unachieved. However, there are a number of new and promising avenues of research including: how we can combine results from primary studies, integration of multiple predictions and applying greater emphasis upon the human aspects of prediction tasks. I conclude that the field is likely to remain very challenging due to the people-centric nature of software engineering, since it is in essence a design task. Nevertheless the need for good economic models will grow rather than diminish as software becomes increasingly ubiquitous.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4221628,Martin Shepperd,"FOSE '07: 2007 Future of Software Engineering , May 2007",1
Status of Empirical Research in Software Engineering,"We provide an assessment of the status of empirical software research by analyzing all refereed articles that appeared in the Journal of Empirical Software Engineering from its first issue in January 1996 through June 2006. The journal publishes empirical software research exclusively and it is the only journal to do so. The main findings are: 1. The dominant empirical methods are experiments and case studies. Other methods (correlational studies, meta analysis, surveys, descriptive approaches, ex post facto studies) occur infrequently; long-term studies are missing. About a quarter of the experiments are replications. 2. Professionals are used somewhat more frequently than students as subjects. 3. The dominant topics studied are measurement/metrics and tools/methods/frameworks. Metrics research is dominated by correlational and case studies without any experiments. 4. Important topics are underrepresented or absent, for example: programming languages, model driven development, formal methods, and others. The narrow focus on a few empirically researched topics is in contrast to the broad scope of software research. ",2013,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6618469,Andreas H?fer and Walter F. Tichy,"Book Series Lecture Notes in Computer Science, Volume 4336/2007, Book Empirical Software Engineering Issues. Critical Assessment and Future Directions, Pages 10-19, SpringerLink Date Monday, June 11, 2007",1
Systematic review of organizational motivations for adopting CMM-based SPI,"Background: Software Process Improvement (SPI) is intended to improve software engineering, but can only be effective if used. To improve SPI's uptake, we should understand why organizations adopt SPI. CMM-based SPI approaches are widely known and studied. Objective: We investigated why organizations adopt CMM-based SPI approaches, and how these motivations relate to organizations' size. Method: We performed a systematic review, examining reasons reported in more than forty primary studies. Results: Reasons usually related to product quality and project performance, and less commonly, to process. Organizations reported customer reasons infrequently and employee reasons very rarely. We could not show that reasons related to size. Conclusion: Despite its origins in helping to address customer-related issues for the USAF, CMM-based SPI has mostly been adopted to help organizations improve project performance and product quality issues. This reinforces a view that the goal of SPI is not to improve process per se, but instead to provide business benefits.",2008,http://dl.acm.org/citation.cfm?id=1365278&CFID=932221225&CFTOKEN=61415952,M. Staples and M. Niazi.,"Information and Software Technology 50 (7-8):605-620, 2008.",1
Systematic review: A systematic review of effect size in software engineering experiments,"An effect size quantifies the effects of an experimental treatment. Conclusions drawn from hypothesis testing results might be erroneous if effect sizes are not judged in addition to statistical significance. This paper reports a systematic review of 92 controlled experiments published in 12 major software engineering journals and conference proceedings in the decade 1993-2002. The review investigates the practice of effect size reporting, summarizes standardized effect sizes detected in the experiments, discusses the results and gives advice for improvements. Standardized and/or unstandardized effect sizes were reported in 29% of the experiments. Interpretations of the effect sizes in terms of practical importance were not discussed beyond references to standard conventions. The standardized effect sizes computed from the reviewed experiments were equal to observations in psychology studies and slightly larger than standard conventions in behavioral science. ",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4052585,"Vigdis By Kampenes, Tore Dyb?, Jo E. Hannay, Dag I. K. Sj?berg","Information and Software Technology,   Volume 49 Issue 11-12, November 2007, Publisher: Butterworth-Heinemann pp. 1073 - 1086",1
Tailoring and Introduction of the Rational Unified Process,RUP is a comprehensive software development process framework that has gained a lot of interest by the industry. One major challenge of taking RUP into use is to tailor it to specific needs and then to introduce it into a development organization. This study presents a review and a systematic assembly of existing studies on the tailoring and introduction of RUP. From a systematic search for study reports on this topic we found that most research is anecdotal and focus on the effects of RUP itself. Only a few number of studies address tailoring and introduction. We have found that tailoring RUP is a considerable challenge by itself and that it must be closely related to existing best practices. We see a tendency of turning from large complete process frameworks towards smaller and more light-weight processes which may impose a smoother transition from process model to process in use. ,2009,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5362562,"Geir Kjetil Hanssen, Finn Olav Bj?rnson and Hans Westerheim","Book Series Lecture Notes in Computer Science, Publisher Springer Berlin / Heidelberg, Volume 4764/2007, Book Software Process Improvement, Pages 7-18, SpringerLink Date Thursday, September 13, 2007",1
Techniques for developing more accessible web applications: a survey towards a process classification,"<p>The Web has become one of the most important communication media, since it is spread all over the world. In order to enable everyone to access this medium, Web accessibility has become an emerging topic, and many techniques have been evolved to support the development of accessible Web content. This paper presents a survey on techniques for Web accessibility and proposes a classification into the processes of ISO/IEC 12207 standard. The survey was carried out applying systematic review principles during the literature review. The results include analysis obtained from the synthesis of 53 studies, selected from an initial set of 844. Although the survey results indicate a growth in research on techniques for design and evaluation of Web applications, they also indicate that several development activities have been poorly addressed by scientific research efforts.</p>",2007,http://dl.acm.org/citation.cfm?id=1297177&CFID=932218671&CFTOKEN=40893134,"Andre Pimenta Freire, Rudinei Goularte, Renata Pontin de Mattos Fortes","SIGDOC '07: Proceedings of the 25th annual ACM international conference on Design of communication , October 2007  , Publisher: ACM",1
The Role of Deliberate Artificial Design Elements in Software Engineering Experiments,"Increased realism in software engineering experiments is often promoted as an important means of increasing generalizability and industrial relevance. In this context, artificiality, e.g., the use of constructed tasks in place of realistic tasks, is seen as a threat. In this paper, we examine the opposite view that deliberately introduced artificial design elements may increase knowledge gain and enhance both generalizability and relevance. In the first part of this paper, we identify and evaluate arguments and examples in favor of and against deliberately introducing artificiality into software engineering experiments. We find that there are good arguments in favor of deliberately introducing artificial design elements to 1) isolate basic mechanisms, 2) establish the existence of phenomena, 3) enable generalization from particularly unfavorable to more favorable conditions (persistence of phenomena), and 4) relate experiments to theory. In the second part of this paper, we summarize a content analysis of articles that report software engineering experiments published over a 10-year period from 1993 to 2002. The analysis reveals a striving for realism and external validity, but little awareness of for what and when various degrees of artificiality and realism are appropriate. Furthermore, much of the focus on realism seems to be based on a narrow understanding of the nature of generalization. We conclude that an increased awareness and deliberation as to when and for what purposes both artificial and realistic design elements are applied is valuable for better knowledge gain and quality in empirical software engineering experiments. We also conclude that time spent on studies that have obvious threats to validity that are due to artificiality might be better spent on studies that investigate research questions for which artificiality is a strength rather than a weakness. However, arguments in favor of artificial design elements should not be used to justify studies - - that are badly designed or that have research questions of low relevance.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4453833,"By Jo Hannay , Magne J?rgensen","Found in: IEEE Transactions on Software Engineering 
Issue Date:March 2008 , pp. 242-259",1
The type of evidence produced by empirical software engineers,"This paper reports on the research published between the years 1997 and 2003 inclusive in the journal of Empirical Software Engineering, drawing on the taxonomy developed by Glass et al. in [3]. We found that the research was somewhat narrow in topic with about half the papers focusing on measurement/metrics, review and inspection; that researchers were almost as interested in formulating as in evaluating; that hypothesis testing and laboratory experiments dominated evaluations; that research was not very likely to focus on people and extremely unlikely to refer to other disciplines. We discuss our findings in the context of making empirical software engineering more relevant to practitioners.",2005,http://dl.acm.org/citation.cfm?id=1083176&CFID=932225534&CFTOKEN=50437810,"Judith Segal, Antony Grinyer, Helen Sharp","REBSE '05: Proceedings of the 2005 workshop on Realising evidence-based software engineering, May 2005, Publisher: ACM, pp. 66-73",1
Where Is the Proof? - A Review of Experiences from Applying MDE in Industry,"<p><p>Model-Driven Engineering (MDE) has been promoted as a solution to handle the complexity of software development by raising the abstraction level and automating labor-intensive and error-prone tasks. However, few efforts have been made at collecting evidence to evaluate its benefits and limitations, which is the subject of this review. We searched several publication channels in the period 2000 to June 2007 for empirical studies on applying MDE in industry, which produced 25 papers for the review. Our findings include industry motivations for investigating MDE and the different domains it has been applied to. In most cases the maturity of third-party tool environments is still perceived as unsatisfactory for large-scale industrial adoption. We found reports of improvements in software quality and of both productivity gains and losses, but these reports were mainly from small-scale studies. There are a few reports on advantages of applying MDE in larger projects, however, more empirical studies and detailed data are needed to strengthen the evidence. We conclude that there is too little evidence to allow generalization of the results at this stage.</p></p>",2008,http://dl.acm.org/citation.cfm?id=1426373&CFID=932208349&CFTOKEN=54965093,Parastoo Mohagheghi and Vegard Dehlen,"Book Series Lecture Notes in Computer Science, Volume 5095/2008, Book Model Driven Architecture ? Foundations and Applications, Pages 432-443, SpringerLink Date Friday, June 06, 2008",1
Cross versus Within-Company Cost Estimation Studies: A Systematic Review,"The objective of this paper is to determine under what circumstances individual organizations would be able to rely on cross-company-based estimation models. We performed a systematic review of studies that compared predictions from cross-company models with predictions from within-company models based on analysis of project data. Ten papers compared cross-company and within-company estimation models; however, only seven presented independent results. Of those seven, three found that cross-company models were not significantly different from within-company models, and four found that cross-company models were significantly worse than within-company models. Experimental procedures used by the studies differed making it impossible to undertake formal meta-analysis of the results. The main trend distinguishing study results was that studies with small within-company data sets (i.e., $20 projects) that used leave-one-out cross validation all found that the within-company model was significantly different (better) from the cross-company model. The results of this review are inconclusive. It is clear that some organizations would be ill-served by cross-company models whereas others would benefit. Further studies are needed, but they must be independent (i.e., based on different data bases or at least different single company data sets) and should address specific hypotheses concerning the conditions that would favor cross-company or within-company models. In addition, experimenters need to standardize their experimental procedures to enable formal meta-analysis, and recommendations are made in Section 3.",2007,http://ieeexplore.ieee.org/abstract/document/4160970/,"By Barbara A. Kitchenham , Emilia Mendes , Guilherme H. Travassos","Found in: IEEE Transactions on Software Engineering ,Issue Date:May 2007 
pp. 316-329",1
A Systematic Review of Software Development Cost Estimation Studies,"This paper aims to provide a basis for the improvement of software-estimation research through a systematic review of previous work. The review identifies 304 software cost estimation papers in 76 journals and classifies the papers according to research topic, estimation approach, research approach, study context and data set. A Web-based library of these cost estimation papers is provided to ease the identification of relevant estimation research results. The review results combined with other knowledge provide support for recommendations for future software cost estimation research, including: 1) increase the breadth of the search for relevant studies, 2) search manually for relevant papers within a carefully selected set of journals when completeness is essential, 3) conduct more studies on estimation methods commonly used by the software industry, and 4) increase the awareness of how properties of the data sets impact the results when evaluating estimation methods",2007,http://ieeexplore.ieee.org/abstract/document/4027147/,"By Magne Jorgensen , Martin Shepperd","Found in: IEEE Transactions on Software Engineering ,Issue Date:January 2007 
pp. 33-53",1
A Survey of Controlled Experiments in Software Engineering,"The classical method for identifying cause-effect relationships is to conduct controlled experiments. This paper reports upon the present state of how controlled experiments in software engineering are conducted and the extent to which relevant information is reported. Among the 5,453 scientific articles published in 12 leading software engineering journals and conferences in the decade from 1993 to 2002, 103 articles (1.9 percent) reported controlled experiments in which individuals or teams performed one or more software engineering tasks. This survey quantitatively characterizes the topics of the experiments and their subjects (number of subjects, students versus professionals, recruitment, and rewards for participation), tasks (type of task, duration, and type and size of application) and environments (location, development tools). Furthermore, the survey reports on how internal and external validity is addressed and the extent to which experiments are replicated. The gathered data reflects the relevance of software engineering experiments to industrial practice and the scientific maturity of software engineering research.",2005,http://ieeexplore.ieee.org/abstract/document/1514443/,"By Dag I.K. Sjoberg , Jo E. Hannay , Ove Hansen , Vigdis By Kampenes , Amela Karahasanovic , Nils-Kristian Liborg , Anette C. Rekdal","Found in: IEEE Transactions on Software Engineering
Issue Date:September 2005 , pp. 733-753",1
A Survey on Software Estimation in the Norwegian Industry,"Abstract:
We provide an overview of the estimation methods that software companies apply to estimate their projects, why those methods are chosen, and how accurate they are. In order to improve estimation accuracy, such knowledge is essential. We conducted an in-depth survey, where information was collected through structured interviews with senior managers from 18 different companies and project managers of 52 different projects. We analyzed information about estimation approach, effort estimation accuracy and bias, schedule estimation accuracy and bias, delivered functionality and other estimation related information. Our results suggest, for example, that average effort overruns are 41%, that the estimation performance has not changed much the last 10-20 years, that expert estimation is the dominating estimation method, that estimation accuracy is not much impacted by use of formal estimation models, and that software managers tend to believe that the estimation accuracy of their company is better than it actually is.",2004,http://ieeexplore.ieee.org/abstract/document/1357904/,"By Kjetil Molokken-Ostvold , Magne Jorgensen , Sinan S. Tanilkan , Hans Gallis , Anette C. Lien , Siw E. Hove","Found in: 10th IEEE International Symposium on Software Metrics (METRICS'04) 
Issue Date:September 2004 , pp. 208-219",1
A Systematic Review of Theory Use in Software Engineering Experiments,"Empirically based theories are generally perceived as foundational to science. However, in many disciplines, the nature, role and even the necessity of theories remain matters for debate, particularly in young or practical disciplines such as software engineering. This article reports a systematic review of the explicit use of theory in a comprehensive set of 103 articles reporting experiments, from of a total of 5,453 articles published in major software engineering journals and conferences in the decade 1993-2002. Of the 103 articles, 24 use a total of 40 theories in various ways to explain the cause-effect relationship(s) under investigation. The majority of these use theory in the experimental design to justify research questions and hypotheses, some use theory to provide post hoc explanations of their results, and a few test or modify theory. A third of the theories are proposed by authors of the reviewed articles. The interdisciplinary nature of the theories used is greater than that of research in software engineering in general. We found that theory use and awareness of theoretical issues are present, but that theory-driven research is, as yet, not a major issue in empirical software engineering. Several articles comment explicitly on the lack of relevant theory. We call for an increased awareness of the potential benefits of involving theory, when feasible. To support software engineering researchers who wish to use theory, we show which of the reviewed articles on which topics use which theories for what purposes, as well as details of the theories' characteristics",2007,http://ieeexplore.ieee.org/abstract/document/4052585/,"By Jo E. Hannay , Dag I.K. Sjoberg , Tore Dyba","Found in: IEEE Transactions on Software Engineering
Issue Date:February 2007 , pp. 87-107",1
A systematic review of Web engineering research,"Abstract:
This paper uses a systematic literature review as means of investigating the rigor of claims arising from Web engineering research. Rigor is measured using criteria combined from software engineering research. We reviewed 173 papers and results have shown that only 5% would be considered rigorous methodologically. In addition to presenting our results, we also provide suggestions for improvement of Web engineering research based on lessons learnt by the software engineering community.",2005,http://ieeexplore.ieee.org/abstract/document/1541857/,By E. Mendes,"Found in: 2005 International Symposium on Empirical Software Engineering, 2005. 
Issue Date:November 2005 , pp. 10 pp.",1
Are Two Heads Better than One? On the Effectiveness of Pair Programming,"Pair programming is a collaborative approach that makes working in pairs rather than individually the primary work style for code development. Because PP is a radically different approach than many developers are used to, it can be hard to predict the effects when a team switches to PP. Because projects focus on different things, this article concentrates on understanding general aspects related to effectiveness, specifically project duration, effort, and quality. Not unexpectedly, our meta-analysis showed that the question of whether two heads are better than one isn't precise enough to be meaningful. Given the evidence, the best answer is ""it depends"" - on both the programmer's expertise and the complexity of the system and tasks to be solved. Two heads are better than one for achieving correctness on highly complex programming tasks. They might also have a time gain on simpler tasks. Additional studies would be useful. For example, further investigation is clearly needed into the interaction of complexity and programmer experience and how they affect the appropriateness of a PP approach; our current understanding of this phenomenon rests chiefly on a single (although large) study. Only by understanding what makes pairs work and what makes them less efficient can we take steps to provide beneficial work conditions, to avoid detrimental conditions, and to avoid pairing altogether when conditions are detrimental. With the right cooks and the right combination of ingredients, the broth has the potential to be very good indeed.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4375233,"By Tore Dyb? , Erik Arisholm , Dag I.K. Sj?berg , Jo E. Hannay , Forrest Shull","Found in: IEEE Software 
Issue Date:November 2007 , pp. 12-15",1
Do SQA Programs Work - CMM Works. A Meta Analysis,"Many software development professionals and managers of software development organizations are not fully convinced in the profitability of investments for the advancement of SQA systems. The results included in each of the articles we found, cannot lead to general conclusions on the impact of investments in upgrading an SQA system. Our meta analysis was based on CMM level transition (CMMLT) analysis of available publications and was for the seven most common performance metric. The CMMLT analysis is applicable for combined analysis of empirical data from many sources. Each record in our meta analysis database is calculated as ""after-before ratio"", which is nearly free of the studied organization's characteristics. Because the CMM guidelines and SQA requirement are similar, we claim that the results for CMM programs are also applicable to investments in SQA systems. The extensive database of over 1,800 projects from a variety of 19 information sources leading to the meta analysis results - proved that investments in CMM programs and similarly in SQA systems contribute to software development performance.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1421069,"By Daniel Galin , Moti Avrahami","Found in: IEEE International Conference on Software - Science, Technology & Engineering (SwSTE'05) 
Issue Date:February 2005 
pp. 95-100",1
Are CMM Program Investments Beneficial? Analyzing Past Studies,"CMM experts strongly believe that investments in programs promoting an organization's CMM maturity yield substantial organizational and economic benefits. In particular, they argue that CMM programs that implement software process improvements can provide more benefits",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4012629,"By Daniel Galin , Motti Avrahami","Found in: IEEE Software 
Issue Date:November 2006 
pp. 81-87",1
"Capture-recapture in software inspections after 10 years research - theory, evaluation and application.","Software inspection is a method to detect faults in the early phases of the software life cycle. In order to estimate the number of faults?not?found, capture?recapture was introduced for software inspections in 1992 to estimate remaining faults after an inspection. Since then, several papers have been written in the area, concerning the basic theory, evaluation of models and application of the method. This paper summarizes the work made in capture?recapture for software inspections during these years. Furthermore, and more importantly, the contribution of the papers are classified as?theory,?evaluation?or?application, in order to analyse the performed research as well as to highlight the areas of research that need further work. It is concluded that (1) most of the basic theory is investigated within biostatistics, (2) most software engineering research is performed on evaluation, a majority ending up in recommendation of the Mh?JK model, and (3) there is a need for application experiences. In order to support the application, an inspection process is presented with decision points based on capture?recapture estimates.",2004,http://www.sciencedirect.com/science/article/pii/S0164121203000906,"H. Petersson, T. Thelin, P. Runeson, and C. Wohlin.","Journal of Systems and Software 72 (2):249-264, 2004.",1
A systematic review of statistical power in software engineering experiments.,"Statistical power is an inherent part of empirical studies that employ significance testing and is essential for the planning of studies, for the interpretation of study results, and for the validity of study conclusions. This paper reports a quantitative assessment of the statistical power of empirical software engineering research based on the 103 papers on controlled experiments (of a total of 5,453 papers) published in nine major software engineering journals and three conference proceedings in the decade 1993–2002. The results show that the statistical power of software engineering experiments falls substantially below accepted norms as well as the levels found in the related discipline of information systems research. Given this study's findings, additional attention must be directed to the adequacy of sample sizes and research designs to ensure acceptable levels of statistical power. Furthermore, the current reporting of significance tests should be enhanced by also reporting effect sizes and confidence intervals.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4052585,"T. Dyba, V. B. Kampenes, and D. I. K. Sjoberg.","Information and Software Technology 48 (8):745-755, 2006.",1
Software effort estimation terminology: The tower of Babel.,"It is well documented that the software industry suffers from frequent cost overruns. A contributing factor is, we believe, the imprecise estimation terminology in use. A lack of clarity and precision in the use of estimation terms reduces the interpretability of estimation accuracy results, makes the communication of estimates difficult, and lowers the learning possibilities. This paper reports on a structured review of typical software effort estimation terminology in software engineering textbooks and software estimation research papers. The review provides evidence that the term ?effort estimate? is frequently used without sufficient clarification of its meaning, and that estimation accuracy is often evaluated without ensuring that the estimated and the actual effort are comparable. Guidelines are suggested on how to reduce this lack of clarity and precision in terminology.",2006,http://www.sciencedirect.com/science/article/pii/S0950584905000674,"S. Grimstad, M. Jorgensen, and K. Molokken-Ostvold.","Information and Software Technology 48 (4):302-310, 2006.",1
In Search of What We Experimentally Know about Unit Testing,"Gathering evidence in any discipline is a lengthy procedure, requiring experimentation and empirical confirmation to transform information from mere opinion to undisputed fact. Software engineering is a relatively young field and experimental SE is even younger, so undisputed facts are few and far between. Nevertheless, ESE's relevance is growing because experimental results can help practitioners make better decisions. We have aggregated results from unit-testing experiments with the aim of identifying information with some experimental basis that might help practitioners make decisions. Most of the experiments focus on two important characteristics of testing techniques: effectiveness and efficiency. Some other experiments study the quality of test-case sets according to different criteria",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4012628,"By Natalia Juristo , Ana M. Moreno , Sira Vegas , Martin Solari","Found in: IEEE Software 
Issue Date:November 2006 
pp. 72-80",1
Precise Identification of Side-Effect-Free Methods in Java,"Knowing which methods do not have side effects is necessary in a variety of software tools for program understanding, restructuring, optimization, and verification. We present a general approach for identifying side-effect-free methods in Java software. Our technique is parameterized by class analysis and is designed to work on incomplete programs. We present empirical results from two instantiations of the approach, based on rapid type analysis and on points-to analysis. In our experiments with several components, on average 22% of the investigated methods were identified as free of side effects. We also present a precision evaluation which shows that the approach achieves almost perfect precision - i.e., it almost never misses methods that in reality have no side effects. These results indicate that very precise identification of side-effect-free methods is possible with simple and inexpensive analysis techniques, and therefore can be easily incorporated in software tools.",2004,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1357793,By Atanas Rountev,"Found in: 20th IEEE International Conference on Software Maintenance (ICSM'04) 
Issue Date:September 2004 
pp. 82-91",1
Reviewing 25 Years of Testing Technique Experiments,"Mature knowledge allows engineering disciplines the achievement of predictable results. Unfortunately, the type of knowledge used in software engineering can be considered to be of a relatively low maturity, and developers are guided by intuition, fashion or market-speak rather than by facts or undisputed statements proper to an engineering discipline. Testing techniques determine different criteria for selecting the test cases that will be used as input to the system under examination, which means that an effective and efficient selection of test cases conditions the success of the tests. The knowledge for selecting testing techniques should come from studies that empirically justify the benefits and application conditions of the different techniques. This paper analyzes the maturity level of the knowledge about testing techniques by examining existing empirical studies about these techniques. We have analyzed their results, and obtained a testing technique knowledge classification based on their factuality and objectivity, according to four parameters.",2004,https://link.springer.com/article/10.1023%2FB%3AEMSE.0000013513.48963.1b?LI=true,"Natalia Juristo, Ana M. Moreno, Sira Vegas","March 2004 
Empirical Software Engineering,   Volume 9 Issue 1-2 
Publisher: Kluwer Academic Publishers",1
What Do We Know about Defect Detection Methods?,"A survey of defect detection studies comparing inspection and testing techniques yields practical recommendations: use inspections for requirements and design defects, and use testing for code. Evidence-based software engineering can help software practitioners decide which methods to use and for what purpose. EBSE involves defining relevant questions, surveying and appraising avail able empirical evidence, and integrating and evaluating new practices in the target environment. This article helps define questions regarding defect detection techniques and presents a survey of empirical studies on testing and inspection techniques. We then interpret the findings in terms of practical use. The term defect always relates to one or more underlying faults in an artifact such as code. In the context of this article, defects map to single faults",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1628944,"By Per Runeson , Carina Andersson , Thomas Thelin , Anneliese Andrews , Tomas Berling","Found in: IEEE Software Issue Date:May 2006 
pp. 82-90",1
On the success of empirical studies in the international conference on software engineering,"Critiques of the quantity and quality of empirical evaluations in software engineering have existed for quite some time. However such critiques are typically not empirically evaluated. This paper fills this gap by empirically analyzing papers published by ICSE, the prime research conference on Software Engineering. We present quantitative and qualitative results of a quasi-random experiment of empirical evaluations over the lifetime of the conference. Our quantitative results show the quantity of empirical evaluation has increased over 29 ICSE proceedings but we still have room to improve the soundness of empirical evaluations in ICSE proceedings. Our qualitative results point to specific areas of improvement in empirical evaluations.",2006,http://dl.acm.org/citation.cfm?id=1134333,"Carmen Zannier, Grigori Melnik, Frank Maurer","ICSE '06: Proceedings of the 28th international conference on Software engineering, May 2006,  Publisher: ACM",1
A critical evaluation of literature on visual aesthetics for the web,<p>This paper reviews the current state of literature on visual aesthetics for the web. This was done by referring to recent contributions of authors in the area of visual aesthetics. Specific focus areas included: authors' perception of the importance of visual aesthetics; how visual aesthetics affect communication; and guidelines and suggestions on how to apply visual aesthetics. The authors also briefly suggest an appropriate research approach when studying visual aesthetics.</p>,2004,http://dl.acm.org/citation.cfm?id=1035077&CFID=932219829&CFTOKEN=90709481,"Ralf Hoffmann, Kirstin Krauss","SAICSIT '04: Proceedings of the 2004 annual research conference of the South African institute of computer scientists and information technologists on IT research in developing countries, October 2004, Publisher: South African Institute for Computer Scientists and Information Technologists",0
A fault-tolerant approach to test control utilizing dual-redundant processors,"A simple dual-redundant fault-tolerant test control system architecture has been designed, developed, and demonstrated in a real-time environment using inexpensive personal computers. A survey of existing fault-tolerant control systems was performed to assess the relative cost and capabilities of currently available technology. A cost-benefit analysis was performed comparing the relative benefit of this system to triplex systems and non-fault-tolerant systems for various applications. Functionally identical implementations of a prototype proof-of-concept software design were constructed in two different languages and tested using a unit-under-test model. Bugs (faults) were injected into this model to verify the ability of the system to reliably detect anomalous test hardware operation. Also, simulated bugs (faults) were introduced to verify smooth control transfer between primary and standby, both nominally and in the presence of hardware-under-tests anomalies. Results indicate significant improvement in system reliability, sufficient to justify the additional cost of the proposed duplex system for many potential users.",2008,http://dl.acm.org/citation.cfm?id=1332154&CFID=932221030&CFTOKEN=92587184,"Richard W. Dabney, Letha Etzkorn, Glenn W. Cox","Advances in Engineering Software,   Volume 39 Issue 5, May 2008, Publisher: Elsevier Science Ltd.",0
A First Approach to a Data Quality Model for Web Portals,"Advances in technology and the use of the Internet have favoured the emergence of a large number of Web applications, including Web Portals. Web portals provide the means to obtain a large amount of information therefore it is crucial that the information provided is of high quality. In recent years, several research projects have investigated Web Data Quality; however none has focused on data quality within the context of Web Portals. Therefore, the contribution of this research is to provide a framework centred on the point of view of data consumers, and that uses a probabilistic approach for Web portal's data quality evaluation. This paper shows the definition of operational model, based in our previous work.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4335242,"Angelica Caro, Coral Calero, Ismael Caballero and Mario Piattini","Book Series Lecture Notes in Computer Science, Volume 3982/2006, Book Computational Science and Its Applications - ICCSA 2006, Pages 984-993, SpringerLink Date Thursday, May 11, 2006",0
A Framework for Understanding the Factors Influencing Pair Programming Success,"<p>Pair programming is one of the more controversial aspects of several Agile system development methods, in particular eXtreme Programming (XP). Various studies have assessed factors that either drive the success or suggest advantages (and disadvantages) of pair programming. In this exploratory study the literature on pair programming is examined and factors distilled. These factors are then compared and contrasted with those discovered in our recent Delphi study of pair programming. Gallis et al. (2003) have proposed an initial framework aimed at providing a comprehensive identification of the major factors impacting team programming situations including pair programming. However, this study demonstrates that the framework should be extended to include an additional category of factors that relate to organizational matters. These factors will be further refined, and used to develop and empirically evaluate a conceptual model of pair programming (success).</p>",2005,http://dl.acm.org/citation.cfm?id=2135004&CFID=932216336&CFTOKEN=36192593,"Mustafa Ally, Fiona Darroch and Mark Toleman","Book Series Lecture Notes in Computer Science, Volume 3556/2005, Book Extreme Programming and Agile Processes in Software Engineering, Pages 82-91, SpringerLink Date Tuesday, May 24, 2005",0
A Methodology for Identifying Critical Success Factors That Influence Software Process Improvement Initiatives: An Application in the Brazilian Software Industry,"<p>Continuous improvement of software development capability is fundamental for organizations to thrive in competitive markets. Nevertheless, Software Process Improvement (SPI) initiatives have demonstrated limited results because SPI managers usually fail to cope with factors that have influence on the success of SPI. In this paper, we present the results of a multistrategy approach aiming to identify critical success factors (CSF) that have influence on SPI. The study results were confirmed by the literature review. The CSF were identified through a combination of qualitative and quantitative analyses of the results of a survey we conducted with SPI practitioners involved in Brazilian software industry experiences. We also identified the relationships of major factors that emerged from the survey. We expect that the major CSF presented in this paper can be used by SPI managers in the definition of SPI strategies aiming to enhance SPI initiatives success.</p>",2007,http://dl.acm.org/citation.cfm?id=2396189&CFID=932212135&CFTOKEN=75362817,Mariano Montoni and Ana Regina Rocha,"Book Series Lecture Notes in Computer Science,. Volume 4764/2007, Book Software Process Improvement, Pages 175-186, SpringerLink Date Thursday, September 13, 2007",0
A Model for Requirements Change Management: Implementation of CMMI Level 2 Specific Practice,"<p><p>OBJECTIVE --- The objective of this research is to implement CMMI Level 2 specific practice --- SP 1.3-1 manage requirements changes. In this paper we have proposed a model for requirements change management and also discussed initial validation of this model. This model is based on both an empirical study that we have carried out and our extensive literature review of software process improvement (SPI) and requirements engineering (RE).</p><p>METHOD --- For data collection we have interviewed SPI experts from reputed organisations. Further work includes analysing research articles, published experience reports and case studies. The initial evaluation of the model was performed via an expert review process.</p><p>RESULTS --- Our model is based on five core elements identified from literature and interviews: request, validate, implement, verify and update. Within each of these elements we have identified specific activities that need to take place during requirements change management process.</p><p>CONCLUSIONS --- The initial evaluation of the model shows that the requirements change management model is clear, easy to use and can effectively manage the requirements change process. However, more case studies are needed to evaluate this model in order to further evaluate its effectiveness in the domain of RE process.</p></p>",2008,http://dl.acm.org/citation.cfm?id=1425912&CFID=932208409&CFTOKEN=45987932,"Mahmood Niazi, Charles Hickman, Rashid Ahmad and Muhammad Ali Babar","Book Series Lecture Notes in Computer Science, Volume 5089/2008, Book Product-Focused Software Process Improvement, Pages 143-157, SpringerLink Date Tuesday, June 17, 2008",0
A Strategic Descriptive Review of the Intelligent Decision-making Support Systems Research: the 1980?2004 Period,"Abstract About 25 years ago, the Nobel laureate Herbert A. Simon and other top Management Science/Operations Research (MS/OR) and Artificial Intelligence (AI) researchers, suggested that an integration of the two disciplines would improve the design of decision-making support tools in organizations. The suggested integrated system has been called an intelligent decision-making support system (i-DMSS). In this chapter, we use an existing conceptual framework posed to assess the capabilities and limitations of the i-DMSS concept, and through a conceptual metaanalysis research of the Decision Support System (DSS) and AI literature from 1980 to 2004, we develop a strategic assessment of the initial proposal. Such an analysis reveals support gaps that suggest further development of the initial i-DMSS concept is needed. We offer recommendations for making the indicated improvements in i-DMSS design, development, and application.",2006,http://dx.doi.org/10.1007/1-84628-231-4_23,"Manuel Mora, Guisseppi Forgionne, Jatinder Gupta, Leonardo Garrido, Francisco Cervantes and Ovsei Gelman","Book Series Decision Engineering, Book Intelligent Decision-making Support Systems, Pages 441-462, SpringerLink Date Friday, March 30, 2007",0
A Survey of Software Estimation Techniques and Project Planning Practices,"Paper provides in depth review of software and project estimation techniques existing in industry and literature, its strengths and weaknesses. Usage, popularity and applicability of such techniques are elaborated. In order to improve estimation accuracy, such knowledge is essential. Many estimation techniques, models, methodologies exists and applicable in different categories of projects. None of them gives 100% accuracy but proper use of them makes estimation process smoother and easier. Organizations should automate estimation procedures, customize available tools and calibrate estimation approaches as per their requirements. Proposed future work is to study factors involved in Software Engineering Approaches (Software Estimation in focus) for Offshore and Outsourced Software Development taking Pakistani IT Industry as a Case Study",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1640709,By Mehwish Nasir,"Found in: Seventh ACIS International Conference on Software Engineering, Artificial Intelligence, Networking, and Parallel/Distributed Computing (SNPD'06) 
Issue Date:June 2006 , pp. 305-310",0
A survey on model-based testing approaches: a systematic review,"This paper describes a systematic review performed on model-based testing (MBT) approaches. A selection criterion was used to narrow the initially identified four hundred and six papers to focus on seventy-eight papers. Detailed analysis of these papers shows where MBT approaches have been applied, the characteristics, and the limitations. The comparison criteria includes representation models, support tools, test coverage criteria, the level of automation, intermediate models, and the complexity. This paper defines and explains the review methodology and presents some results.",2009,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5358707,"Arilo C. Dias Neto, Rajesh Subramanyan, Marlon Vieira, Guilherme H. Travassos","WEASELTech '07: Proceedings of the 1st ACM international workshop on Empirical assessment of software engineering languages and technologies: held in conjunction with the 22nd IEEE/ACM International Conference on Automated Software Engineering (ASE) 2007 , November 2007 , Publisher: ACM",0
A Systematic Review Measurement in Software Engineering: State-of-the-Art in Measures,"The present work provides a summary of the state of art in software measures by means of a systematic review on the current literature. Nowadays, many companies need to answer the following questions: How to measure?, When to measure and What to measure?. There have been a lot of efforts made to attempt to answer these questions, and this has resulted in a large amount of data what is sometimes confusing and unclear information. This needs to be properly processed and classified in order to provide a better overview of the current situation. We have used a Measurement Software Ontology to classify and put the amount of data in this field in order. We have also analyzed the results of the systematic review, to show the trends in the software measurement field and the software process on which the measurement efforts have focused. It has allowed us to discover what parts of the process are not supported enough by measurements, to thus motivate future research in those areas.",2012,http://dl.acm.org/citation.cfm?id=2372274&CFID=932212811&CFTOKEN=64259995,"Oswaldo G?mez, Hanna Oktaba, Mario Piattini and F?lix Garc?a","Book Series Communications in Computer and Information Science, Volume 10, Book Software and Data Technologies, Part 3, Pages 165-176, SpringerLink Date Friday, July 18, 2008",0
Adoption-Centric Software Maintenance Process Improvement via Information Integration,"Software process improvement is an iterative activity, normally involving measurement, analysis, and change. For most organizations, the existing software process has substantial momentum and is seemingly immovable. Any change to existing process activities causes turbulence in the organization, which can be a significant barrier to adoption of the quality improvement initiative. This paper presents a quiescent, non-invasive, and adoption-centric approach to process improvement for software maintenance. The approach realizes the goal of improving the efficiency of existing processes by minimizing changes to existing workflows and focusing on integrating enhancements at the micro-level of the system. By leveraging information buried in existing data, making it explicit, and integrating the results with known facts, more informed decision-making is made possible. The approach is illustrated with a model problem concerning redocumentation of an embedded control system in the context of performing higher-quality software maintenance",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1691628,"By Shihong Huang , Scott Tilley , Mike VanHilst , Damiano Distante","13th IEEE International Workshop on Software Technology and Engineering Practice (STEP'05)  
Issue Date:September 2005 
pp. 25-34",0
Advances in dataflow programming languages.,"Many developments have taken place within dataflow programming languages in the past decade. In particular, there has been a great deal of activity and advancement in the field of dataflow visual programming languages. The motivation for this article is to review the content of these recent developments and how they came about. It is supported by an initial review of dataflow programming in the 1970s and 1980s that led to current topics of research. It then discusses how dataflow programming evolved toward a hybrid von Neumann dataflow formulation, and adopted a more coarse-grained approach. Recent trends toward dataflow visual programming languages are then discussed with reference to key graphical dataflow languages and their development environments. Finally, the article details four key open topics in dataflow programming languages.",1994,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=265657,"W. M. Johnston, J. R. P. Hanna, and R. J. Millar.","Acm Computing Surveys 36 (1):1-34, 2004.",0
Agile Methods: The Gap between Theory and Practice,"Since the software crisis of the 1960’s, numerous methodologies have been developed to impose a disciplined process upon software development. Today, these methodologies are noted for being unsuccessful and unpopular due to their increasingly bureaucratic nature. Many researchers and academics are calling for these heavyweight methodologies to be replaced by agile methods. However, there is no consensus as to what constitutes an agile method. An Agile Manifesto was put forward in 2001, but many variations, such as XP, SCRUM and Crystal exist. Each adheres to some principles of the Agile Manifesto and disregards others. My research proposes that these principles lack grounding in theory, and lack a respect for the concept of agility outside the field of Information Systems Development (ISD). This study aims to develop a comprehensive framework of ISD agility, to determine if this framework is adhered to in practice and to determine if such adherence is rewarded. The framework proposes that it is insufficient to just accept agile methods as superior to all others. In actual fact, an ISD team have to identify whether they need to be agile, and to compare this to their agile capabilities before deciding how agile their eventual method should be. Furthermore this study proposes that an agile method is not just accepted and used. Rather it may be selected from a portfolio of methods, it may be constructed from parts of methods, or indeed it may be the product of the ISD team’s deviation from a different method altogether. Finally, this study recognises that agility does not simply come from a method. In actual fact, a cross-disciplinary literature review suggests that it is important to classify sources of agility, which could be the people on team, the way they are organised, the technology they use or the external environment with which they interact. A three phase research method is adopted, incorporating a set of pilot interviews, a large-scale survey and finally, a set of case studies. The survey is intended to produce generalisable results while the case studies are carried out to obtaining much needed qualitative information in an emerging field where little is currently known.",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7271174,Kieran Conboy,"Book Series Lecture Notes in Computer Science, Volume 3092/2004, Book Extreme Programming and Agile Processes in Software Engineering, Page 316, SpringerLink Date Friday, May 14, 2004",0
An Empirical Exploration of the Distributions of the Chidamber and Kemerer Object-Oriented Metrics Suite,"<p>The object-oriented metrics suite proposed by Chidamber and Kemerer (CK) is a measurement approach towards improved object-oriented design and development practices. However, existing studies evidence traces of collinearity between some of the metrics and low ranges of other metrics, two facts which may endanger the validity of models based on the CK suite. As high correlation may be an indicator of collinearity, in this paper, we empirically determine to what extent high correlations and low ranges might be expected among CK metrics.</p><p>To draw as much general conclusions as possible, we extract the CK metrics from a large data set (200 public domain projects) and we apply statistical meta-analysis techniques to strengthen the validity of our results. Homogenously through the projects, we found a moderate (&sim;0.50) to high correlation (&gt;0.80) between some of the metrics and low ranges of other metrics.</p><p>Results of this empirical analysis supply researchers and practitioners with three main advises: a) to avoid the use in prediction systems of CK metrics that have correlation more than 0.80 b) to test for collinearity those metrics that present moderate correlations (between 0.50 and 0.60) c) to avoid the use as response in continuous parametric regression analysis of the metrics presenting low variance. This might therefore suggest that a prediction system may not be based on the whole CK metrics suite, but only on a subset consisting of those metrics that do not present either high correlation or low ranges.</p>",2005,http://dl.acm.org/citation.cfm?id=1032629&CFID=932218020&CFTOKEN=89258330,"Giancarlo Succi, Witold Pedrycz, Snezana Djokic, Paolo Zuliani, Barbara Russo","Empirical Software Engineering,   Volume 10 Issue 1, January 2005, Publisher: Kluwer Academic Publishers",0
An Empirical Study to Investigate Software Estimation Trend in Organizations Targeting CMMI^SM,"This paper discusses software estimation practices existing in industry and literature, its strengths and weaknesses. Main focus is the gap analysis of organization with respect to CMMI level 3 for SE/SW/IPPD/SS. Data collection reveals that company makes use of heuristic approaches in which expert judgment supplemented with wideband Delphi, was mainly used for software estimation. In the light of CMMI level 3 for SE/SW, it was suggested that formal methods for estimating size, effort and cost for the project should be implemented apart from heuristics used for estimation. Different estimation methodologies are applicable in different categories of projects. None of them gives 100% accuracy but proper use of them makes estimation process smoother. Future work is calibration of parametric software estimation approaches for the organization under study by making use of organizational process database to plan, estimate and tailor project variables that best suits organization's processes and procedures",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1651967,"By Mehwish Nasir , H. Farooq Ahmad","Found in: 5th IEEE/ACIS International Conference on Computer and Information Science and 1st IEEE/ACIS International Workshop on Component-Based Software Engineering,Software Architecture and Reuse (ICIS-COMSAR'06) 
Issue Date:July 2006 , pp. 38-43",0
Architecture-Based Software Reliability Analysis: Overview and Limitations,"With the growing size and complexity of software applications, research in the area of architecture-based software reliability analysis has gained prominence. The purpose of this paper is to provide an overview of the existing research in this area, critically examine its limitations, and suggest ways to address the identified limitations",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4099190,By Swapna S. Gokhale,"IEEE Transactions on Dependable and Secure Computing
Issue Date:January 2007 
pp. 32-40",0
Autonomic and Trusted Computing Paradigms,"The emerging autonomic computing technology has been hailed by world-wide researchers and professionals in academia and industry. Besides four key capabilities, well known as self-CHOP, we propose an additional self-regulating capability to explicitly emphasize the policy-driven self-manageability and dynamic policy derivation and enactment. Essentially, these five capabilities, coined as Self-CHROP, define an autonomic system along with other minor properties. Trusted computing targets guaranteed secured systems. Self-protection alone does not ensure the trustworthiness in autonomic systems. The new trend is to integrate both towards trusted autonomic computing systems. This paper presents a comprehensive survey of the autonomic and trusted computing paradigms and a preliminary conceptual architecture towards trustworthy autonomic grid computing.",2013,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6673090,"Xiaolin Li, Hui Kang, Patrick Harrington and Johnson Thomas","Book Series Lecture Notes in Computer Science, Volume 4158/2006, Book Autonomic and Trusted Computing, Pages 143-152, SpringerLink Date Wednesday, October 04, 2006",0
Building Reverse Engineering Tools with Software Components: Ten Lessons Learned,"My dissertation explores a new approach to construct tools in the domain of reverse engineering. The approach uses already available software components as building blocks, combining and customizing them programmatically. This approach can be characterized as component-based tool-building. The goal of the dissertation is to advance the current state of component-based tool-building towards a discipline that is more predictable and formal. This is achieved with three research contributions: (1) an in-depth literature survey that identifies requirements for reverse engineering tools, (2) a number of tool case studies that utilize component-based tool-building, (3) and ten lessons learned for tool builders that have been distilled from these case studies.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4400180,By Holger M. Kienle,"Found in: 14th Working Conference on Reverse Engineering (WCRE 2007) 
Issue Date:October 2007 
pp. 289-292",0
Case Study of Breakdown Analysis on Identification of Remote Team Communication Problems,"<p>The purpose is to apply breakdown analysis in identifying problems of distributed communication. Sample comprises Intranet and Internet teams. The methodology is breakdown analysis. Research framework comprises user-user, user-tool and user-task. The tools include videoconferencing and data conferencing. Transcript coding and qualitative analysis were followed. Procedures include literature review, development of framework, sampling, tool setup and breakdown analysis. Five problem indicators of user-user included unclearness of participant&#39;s oral expression, disagreement, off-task, no answer and keep silence. Problem indicators of user-tool were incorrect configuration, unstable facilities and broadband, unfamiliarity with application and facilities. User-task problem indicators included uncompleted task, participant&#39;s lateness and ignorance of assigned task. Causes of problems included participant&#39;s familiarity, ignorance of task and lateness in meeting. There was no difference of problem indicators between Intranet and Internet connection. Implications included consideration of participant&#39;s familiarity, asynchronous communica-tion is in need during inter-meeting and better planning and preparation of facilitator.</p>",2005,http://dl.acm.org/citation.cfm?id=2096367&CFID=932218301&CFTOKEN=93603127,Lai-Chung Lee and Whei-Jane Wei,"Book Series Lecture Notes in Computer Science, Volume 3865/2006, Book Computer Supported Cooperative Work in Design II, Pages 122-130, SpringerLink Date Sunday, February 26, 2006",0
Changing perceptions of CASE technology,"The level to which CASE technology has been successfully deployed in IS and software development organisations has been at best variable. Much has been written about an apparent mismatch between user expectations of the technology and the products which are developed for the growing marketplace. In this paper we explore how this tension has developed over time, with the aim of identifying and characterising the major factors contributing to it. We identify three primary themes: volatility and plurality in the marketplace; the close relationship between tools and development methods; and the context sensitivity of feature assessment. By exploring the tension and developing these themes we hope to further the debate on how to improve evaluation of CASE prior to adoption.",2009,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5420441,"Lundell, B.a , Lings, B.b","(2004) Journal of Systems and Software, 72 (2), pp. 271-280. Cited 5 times.",0
Cognitive differences between procedural programming and object oriented programming,"Software development is moving from procedural programming towards object-oriented programming (OOP). Past studies in cognitive aspects of programming have focused primarily on procedural programming languages. Object-oriented programming is a new paradigm for computing. Industry is finding that programmers are having difficulty shifting to this new programming paradigm.

Findings in prior research revealed that procedural programming requires Piaget's formal operation cognitive level. New from this research is that OOP also requires Piaget's formal operation cognitive level. Also new is that OOP appears to be unrelated to hemispheric cognitive style. OOP appears to be hemispheric style friendly, while procedural programming is preferential to left hemispheric cognitive style.

The conclusion is that cognitive requirements are not the cause for the difficulty in shifting from procedural to OOP. An alternative possibility to the difficulty is proactive interference of learning procedural programming prior to learning object oriented programming.",2005,http://dl.acm.org/citation.cfm?id=1093735&CFID=932217147&CFTOKEN=98998217,"White, G., Sivitanides, M.","(2005) Information Technology and Management, 6 (4), pp. 333-350.",0
Combining Behaviour and Structure,,2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5660381,Richard Sharp,"Book Series Lecture Notes in Computer Science, Volume 2963/2004, Book Higher Level Hardware Synthesis, Pages 129-139, SpringerLink Date Friday, March 12, 2004",0
Commonalities in Risk Management and Agile Process Models,"On the surface, agile and risk management process models seem to constitute two contrasting approaches. Risk management follows a heavyweight approach whereas agile process models oppose it. In this paper, we identify commonalities in these two process models. Our results show that they have much in common, and that a merge between them is possible.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4299901,"By Jaana Nyfjord , Mira Kajko-Mattsson","Found in: International Conference on Software Engineering Advances (ICSEA 2007) 
Issue Date:August 2007 
pp. 18",0
Component airbag: a novel approach to develop dependable component-based applications,"The increasing use of ""commercial off-the-shelf"" (COTS) components in safety critical scenarios, arises new issues related to the ""dependable"" use of third-party software in such contexts. The characteristics of these components, designed for a generic use, are such to make unpredictable the effects of their use whenever they are integrated in the entire system. The author's Ph.D project aim at proposing an approach to improve dependability of COTS based application, which consists of the following phases: i) each component is stimulated by proper workloads in order to learn the failure behavior; ii) from failure behaviors, the component failure model is defined; and iii) once the failure model is known for each component, the ""component airbag"" is thus created, i.e. a container able of exploiting the failure model in order to monitor and prevent the component from failing. An existent literature analysis, regarding the more used dependability assessment and improvement strategies, is also presented.",2007,http://dl.acm.org/citation.cfm?id=1295052&CFID=932217904&CFTOKEN=45476425,Roberto Pietrantuono,"ESEC-FSE '07: Proceedings of the the 6th joint meeting of the European software engineering conference and the ACM SIGSOFT symposium on The foundations of software engineering, September 2007, Publisher: ACM",0
Conceptual Modeling for Simulation: Issues and Research Requirements,"It is generally recognized that conceptual modeling is one of the most vital parts of a simulation study. At the same time, it also seems to be one of the least understood. A review of the extant literature on conceptual modeling reveals a range of issues that need to be addressed: the definition of conceptual model(ling), conceptual model requirements, how to develop a conceptual model, conceptual model representation and communication, conceptual model validation, and teaching conceptual modeling. It is clear that this is an area ripe for further research, for the clarification of ideas and the development of new approaches. Some areas in which further research could be carried out are identified",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4117684,By S. Robinson,"Found in: Proceedings of the 2006 Winter Simulation Conference 
Issue Date:December 2006 
pp. 792-800",0
Critic systems - Towards human-computer collaborative problem solving,"Human-computer collaboration is extremely necessary for solving ill-structured problems and critic systems can effectively facilitate human-computer collaborative problem solving. This paper conducts a systematic study on critic systems. First, the concepts of critic systems are presented. Then, a literature review is presented on critic systems. Afterwards, a generic architecture is put forward for critic systems, with its important aspects being analyzed. Finally, two case studies are given to illustrate critic systems.",2016,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7427362,"Tianfield, H., Wang, R.","Critic systems - Towards human-computer collaborative problem solving
(2004) Artificial Intelligence Review, 22 (4), pp. 271-295.",0
Critical success factors for software process improvement implementation: An empirical study,"In this article, we present findings from our recent empirical study of the critical success factors (CSFs) for software process improvement (SPI) implementation with 34 SPI practitioners. The objective of this study is to provide SPI practitioners with sufficient knowledge about the nature of issues that play a positive role in the implementation of SPI programmes in order to assist them in effectively planning SPI implementation strategies. Through our empirical study we identified seven factors (higher management support, training, awareness, allocation of resources, staff involvement, experienced staff and defined SPI implementation methodology) that are generally considered critical for successfully implementing SPI. We also report on a literature survey of CSFs that impact SPI and identify six factors (senior management commitment, staff involvement, staff time and resources, training and mentoring, creating process action teams and reviews). We compared our empirical study results with the literature and confirmed the factors identified in the literature, and also identified two new CSFs (SPI awareness and defined SPI implementation methodology) that were not identified in the literature. Finally, we analyzed the CSFs identified by different groups of practitioners and found that they are aware of what is imperative for the successful implementation of SPI programmes. ",2011,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5917014,"Niazi, M.a b , Wilson, D.c , Zowghi, D.c","(2006) Software Process Improvement and Practice, 11 (2), pp. 193-211. Cited 6 times.",0
Designing Mobile Shared Workspaces for Loosely Coupled Workgroups,"<p>Recent advances in mobile computing devices and wireless communication have brought the opportunity to transport the shared workspace metaphor to mobile work scenarios. Unfortunately, there are few guidelines to support the design of these mobile shared workspaces. This paper proposes a design process and several guidelines to support the modeling of these groupware systems. Particularly, workspaces that support loosely coupled workgroups. The process and guidelines are based on a literature review and authors' experience in the development of mobile shared workspaces.</p>",2007,http://dl.acm.org/citation.cfm?id=1784445&CFID=932216748&CFTOKEN=35418865,"Andr?s Neyem, Sergio F. Ochoa and Jos? A. Pino","Book Series Lecture Notes in Computer Science, Volume 4715/2007, Book Groupware: Design, Implementation, and Use, Pages 173-190, SpringerLink Date Thursday, August 30, 2007",0
Developing an algorithm for si engine diagnosis using parity relations,"Diagnosis is an algorithm for finding and isolating faults in a dynamic system. In 1994, California designated some regulations which were called OBD II. According to these regulations, there is a system installed in an automobile which can analyze the function of the automobile continuously. The decrease of pollution for the expansion of diagnostic system is necessary in the future. To reach the aims of diagnosis, some redundancies are required in the system, either hardware or soft ware. In the hardware redundancy methods, the installation of additional sensors or actuators on the system is required which is costly and takes up a lot of space, whereas in software redundancy methods, this is done with no expense. In this article, one of the software redundancy methods or analytical methods is implied for solving the problem. At first a discussion on literature survey is mentioned, and then a modified mathematical model for SI engine is acquired. The usage of this method and parity space relations, which is a model based method, accomplished the process of diagnosis. Developing a modified SI engine model and diagnosis of MAT sensor which less has been considered besides other components are this article contributions.",2006,http://proceedings.asmedigitalcollection.asme.org/proceeding.aspx?articleid=1603013,"Mostofi, M., Shamekhi, A.H., Ziabasharhagh, M.","(2006) American Society of Mechanical Engineers, Dynamic Systems and Control Division (Publication) DSC, 7 p.",0
Development of software engineering: A research perspective.,"In the past 40 years, software engineering has emerged as an important sub-field of computer science and has made significant contribution to the software industry. Now it is gradually becoming a new independent discipline. This paper presents a survey of software engineering development from a research perspective. Firstly, the history of software engineering is reviewed with focus on the driving forces of software technology, the software engineering framework and the milestones of software engineering development. Secondly, after reviewing the past academic efforts, the current research activities are surveyed and new challenges brought by Internet are analyzed. Software engineering researches and activities in China are also reviewed. The work in Peking University is described as a representative.",2013,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6757849,"H. Mei, D. G. Cao, and F. Q. Yang.","Journal of Computer Science and Technology 21 (5):682-696, 2006.",0
Distributed real time database systems: background and literature review,"<p>Today's real-time systems (RTS) are characterized by managing large volumes of dispersed data making real-time distributed data processing a reality. Large business houses need to do distributed processing for many reasons, and they often must do it in order to stay competitive. So, efficient database management algorithms and protocols for accessing and manipulating data are required to satisfy timing constraints of supported applications. Therefore, new research in distributed real-time database systems (DRTDBS) is needed to investigate possible ways of applying database systems technology to real-time systems. This paper first discusses the performance issues that are important to DRTDBS, and then surveys the research that has been done so far on the issues like priority assignment policy, commit protocols and optimizing the use of memory in non-replicated/replicated environment pertaining to distributed real time transaction processing. In fact, this study provides a foundation for addressing performance issues important for the management of very large real time data and pointer to other publications in journals and conference proceedings for further investigation of unanswered research questions.</p>",2008,http://dl.acm.org/citation.cfm?id=1345963&CFID=932220433&CFTOKEN=21413890,"Udai Shanker, Manoj Misra and Anil K. Sarje","Journal Distributed and Parallel Databases,. Volume 23, Number 2 / April, 2008, SpringerLink Date Saturday, January 26, 2008",0
Effective Data Interpretation,"Data interpretation is an essential element of mature software project management and empirical software engineering. As far as project management is concerned, data interpretation can support the assessment of the current project status and the achievement of project goals and requirements. As far as empirical studies are concerned, data interpretation can help to draw conclusions from collected data, support decision making, and contribute to better process, product, and quality models. With the increasing availability and usage of data from projects and empirical studies, effective data interpretation is gaining more importance. Essential tasks such as the data-based identification of project risks, the drawing of valid and usable conclusions from individual empirical studies, or the combination of evidence from multiple studies require sound and effective data interpretation mechanisms. This article sketches the progress made in the last years with respect to data interpretation and states needs and challenges for advanced data interpretation. In addition, selected examples for innovative data interpretation mechanisms are discussed. ",2016,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7849384,Jrgen Mnch,"Book Series Lecture Notes in Computer Science, Volume 4336/2007, Book Empirical Software Engineering Issues. Critical Assessment and Future Directions, Pages 83-90, SpringerLink Date Monday, June 11, 2007",0
Embedded Systems Development: Quest for Productivity and Reliability,"It is widely agreed that the state of art in methodologies, techniques and tools for embedded systems development is many years behind their desktop counterparts. The job of the embedded software developer is further complicated by the increasing tendency of system designers to shift functionality and complexity away from hardware and into software. As part of an ongoing research at Philips Semiconductors, we have been investigating solutions to the two main problems of productivity and reliability in embedded software development. This paper describes our research effort in this investigation. Specifically, the paper first describes the requirements on embedded systems and their development challenges. It then provides a literature survey of some techniques that address the issues of productivity and reliability. With this background the paper proposes a model driven architectural approach to embedded software development.",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1595745,"By Abdelgadir E. Ibrahim , Liping Zhao , John Kinghorn","Found in: Fifth International IEEE Conference on Commercial-off-the-Shelf (COTS)-Based Software Systems (ICCBSS'06) 
Issue Date:February 2006 
pp. 23-32",0
Empiricism in Computer Science,"As the name computer science already implies, the study of computers is a field of science.
Computer Science (CS) as it exists today lacks to a certain extent, what other sciences rely
most on: An empirical body of knowledge. This paper looks at several meta studies which
have analyzed the presence of empirical data on CS subjects. It also provides an overview of
empiricism in general, some empirical concepts and where computer science and empiricism
intersect.",1992,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=624546,Eike Send,"Seminar ?Open Source Software Engineering?
Winterterm 2004",0
Empowering the users? A critical textual analysis of the role of users in open source software development,"<p>This paper outlines a critical, textual approach for the analysis of the relationship between different actors in information technology (IT) production, and further concretizes the approach in the analysis of the role of users in the open source software (OSS) development literature. Central concepts of the approach are outlined. The role of users is conceptualized as <i>reader involvement</i> aiming to contribute to the <i>configuration of the reader</i> (to how users and the parameters for their work practices are defined in OSS texts). Afterwards, OSS literature addressing <i>reader involvement</i> is critically reviewed. In OSS context, the OSS writers as readers <i>configure the reader</i> and other readers are assumed to be capable of and interested in commenting the texts. A lack of OSS research on non-technical reader involvement is identified. Furthermore, not only are the OSS readers configured, but so are OSS writers. In OSS context while writers may be empowered, this clearly does not apply to the non-technical OSS readers. Implication for research and practice are discussed.</p>",2008,http://dl.acm.org/citation.cfm?id=1453018&CFID=932219391&CFTOKEN=21730739,Netta Iivari,"Journal AI & Society, Category Original Article, Journal AI & Society, SpringerLink Date Tuesday, July 29, 2008
SpringerLink Date Tuesday, July 29, 2008",0
Engineering the Ontology for the SWEBOK: Issues and Techniques,"Auyang [2] described engineering as “the science of production”. This and many other 
definitions of engineering put an emphasis on disciplined artifact creation as the essence of 
any engineering discipline. However, the material object produced by every engineering 
discipline is not necessarily of a similar nature. The case of software engineering is 
particularly relevant in the illustration of such differences, since software as an artifact is",2003,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1241207,"Alain Abran, Juan Cuadrado, Elena Garc?a-Barriocanal, Olavo Mendes, Salvador S?nchez-Alonso and Miguel Sicilia","Book Ontologies for Software Engineering and Software Technology, Pages 103-121, SpringerLink Date Thursday, October 12, 2006",0
"Ethnography, scenario-based observational usability study, and other reviews inform the design of a web-based E-notebook","As users turn to the World Wide Web to accomplish an increasing variety of daily tasks, many engage in information assimilation (IA), a process defined as the gathering, editing, annotating, organizing, and saving of Web information, and the tracking of ongoing Web work processes. The process of IA, which is similar to traditional note taking but in the Web environment, emerges from a literature review and an ethnographic field study, as presented in this article. Despite strong evidence which suggests that IA is critical to many Web users, however, a scenario-based observational usability study and a heuristic evaluation indicate that it is currently not well supported by existing software applications. This article, which culminates in the presentation of NetNotes-a Web-based e-notebook developed specifically to support the process of IA-illustrates how design requirements can be effectively extracted and synthesized from a variety of complementary background user studies.",2004,http://www.tandfonline.com/doi/abs/10.1207/s15327590ijhc1703_6,"Reimer, Y.J.a c , Douglas, S.A.b","(2005) Information Technology and People, 18 (3), pp. 196-211.",0
Evaluating Quality in Model-Driven Engineering,"In model-driven engineering (MDE), models are the prime artifacts, and developing high-quality systems depends on developing high-quality models and performing transformations that preserve quality or even improve it. This paper presents quality goals in MDE and states that the quality of models is affected by the quality of modeling languages, tools, modeling processes, the knowledge and experience of modelers, and the quality assurance techniques applied. The paper further presents related work on these factors and identifies pertinent research challenges. Some quality goals such as well-formedness and precision are especially important in MDE. Research on quality in MDE can promote adoption of MDE for complex system engineering.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4273246,"By Parastoo Mohagheghi , Jan Aagedal","Found in: International Workshop on Modeling in Software Engineering (MISE'07: ICSE Workshop 2007) 
Issue Date:May 2007 , pp. 6",0
Evaluating Software Project Prediction Systems,"The problem of developing usable software project cost prediction systems is perennial and there are many competing approaches. Consequently, in recent years there have been exhortations to conduct empirically based evaluations in order that our understanding of project prediction might be based upon real world evidence. We now find ourselves in the interesting position of possessing this evidence in abundance. For example, a review of just three software engineering journals identified 50 separate studies and overall several hundred studies have been published. This naturally leads to the next step of needing to construct a body of knowledge, particularly when not all evidence is consistent. This process of forming a body of knowledge is generally referred to as metaanalysis. It is an essential activity if we are to have any hope of making sense of, and utilising, results from our empirical studies. However, it becomes apparent that when systematically combining results many difficulties are encountered",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509280,By Martin Shepperd,"Found in: 11th IEEE International Software Metrics Symposium (METRICS'05) 
Issue Date:September 2005 , pp. 2",0
Evolutionary Scheduling: A Review,"Early and seminal work which applied evolutionary computing methods to scheduling problems from 1985 onwards laid a strong and exciting foundation for the work which has been reported over the past decade or so. A survey of the current state-of-the-art was produced in 1999 for the European Network of Excellence on Evolutionary Computing EVONET¿this paper provides a more up-to-date overview of the area, reporting on current trends, achievements, and suggesting the way forward.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4227533,"Emma Hart, Peter Ross and David Corne","Journal Genetic Programming and Evolvable Machines, Issue Volume 6, Number 2 / June, 2005, Pages 191-220, SpringerLink Date Thursday, February 17, 2005",0
Experiences from Conducting Semi-structured Interviews in Empirical Software Engineering Research,"Many phenomena related to software development are qualitative in nature. Relevant measures of such phenomena are often collected using semi-structured interviews. Such interviews involve high costs, and the quality of the collected data is related to how the interviews are conducted. Careful planning and conducting of the interviews are therefore necessary, and experiences from interview studies in software engineering should consequently be collected and analyzed to provide advice to other researchers. We have brought together experiences from 12 software engineering studies, in which a total of 280 interviews were conducted. Four areas were particularly challenging when planning and conducting these interviews; estimating the necessary effort, ensuring that the interviewer had the needed skills, ensuring good interaction between interviewer and interviewees, and using the appropriate tools and project artifacts. The paper gives advice on how to handle these areas and suggests what information about the interviews should be included when reporting studies where interviews have been used in data collection. Knowledge from other disciplines is included. By sharing experience, knowledge about the accomplishments of software engineering interviews is increased and hence, measures of high quality can be achieved",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509301,"By Siw Elisabeth Hove , Bente Anda","Found in: 11th IEEE International Software Metrics Symposium (METRICS'05) 
Issue Date:September 2005 
pp. 23",0
Exploring the Computing Literature Using Temporal Graph Visualization,"We present a system for the visualization of computing literature with an emphasis on collaboration patterns, interactions between related research specialties and the evolution of these characteristics through time. Our computing literature visualization system, has four major components: A mapping of bibliographical data to relational schema coupled with an RDBMS to store the relational data, an interactive GUI that allows queries and the dynamic construction of graphs, a temporal graph layout algorithm, and an interactive visualization tool. We use a novel technique for visualization of large graphs that evolve through time. Given a dynamic graph, the layout algorithm produces two-dimensional representations of each timeslice, while preserving the mental map of the graph from one slice to the next. A combined view, with all the timeslices can also be viewed and explored. For our analysis we use data from the Association of Computing Machinery's Digital Library of Scientific Literature which contains more than one hundred thousand research papers and authors. Our system can be found online at http://tgrip.cs.arizona.edu.",2004,http://proceedings.spiedigitallibrary.org/proceeding.aspx?articleid=837013,"C. Erten, P. J. Harding, S. G. Kobourov, K. Wampler and G. Yee",Conference on Visualization and Data Analysis (VDA) 2004,0
Figure Out the Current Software Requirements Engineering - What Practitioners Expect to Requirements Engineering? -,"This research aims to grasp and describe what Requirements Engineering(RE) covers, what RE tries to solve and what should RE be in the future. For these purposes, the authors did the literature survey and interviews with the authorities of RE and practitioners. The literature survey targeted over 700 papers and reports published from 2001 to 2005 in major RE conferences and journals in order to capture the influential papers and the trend of topics. The interviews targeted 13 authorities in RE academic field and 7 practitioners who have much knowledge and experiences of RE. One of the most important results of this study is the RE area quadrant which shows the overview of RE field. This quadrant supports to find out what topics of RE would be effective for practitioners' issue. Another important finding is the gap between practitioners' expectation and researchers work from the interviews to both sides. This research helps to know the current figure of RE and helps to know what RE should tackle with.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4425841,"Mayumi Itakura Kamata, Ai Yoshimoto Yoshida, Hisashi Yoshida, Nao Aoki","APSEC '07: Proceedings of the 14th Asia-Pacific Software Engineering Conference, December 2007, Publisher: IEEE Computer Society",0
Forward and Bidirectional Planning Based on Reinforcement Learning and Neural Networks in a Simulated Robot,"Building intelligent systems that are capable of learning, acting reactively and planning actions before their execution is a major goal of artificial intelligence. This paper presents two reactive and planning systems that contain important novelties with respect to previous neural-network planners and reinforcement-learning based planners: (a) the introduction of a new component (matcher) allows both planners to execute genuine taskable planning (while previous reinforcement-learning based models have used planning only for speeding up learning); (b) the planners show for the first time that trained neural-network models of the world can generate long prediction chains that have an interesting robustness with regards to noise; (c) two novel algorithms that generate chains of predictions in order to plan, and control the flows of information between the systems different neural components, are presented; (d) one of the planners uses backward predictions to exploit the knowledge of the pursued goal; (e) the two systems presented nicely integrate reactive behavior and planning on the basis of a measure of confidence in action. The soundness and potentialities of the two reactive and planning systems are tested and compared with a simulated robot engaged in a stochastic path-finding task. The paper also presents an extensive literature review on the relevant issues.",2003,http://dx.doi.org/DOItmp_0558_001437,Gianluca Baldassarre,"Book Series Lecture Notes in Computer Science, Volume 2684/2004, Book Anticipatory Behavior in Adaptive Learning Systems, Pages 87-106, SpringerLink Date Thursday, February 19, 2004",0
From Autonomy to AOC,"Autonomy oriented computing (AOC) is a new bottom-up paradigm for
problem solving and complex systems modeling. In this book, our goal is
to substantiate this very statement and to demonstrate useful AOC methodologies
and applications. But, before we do so, we need to understand some of
the most fundamental issues involved: What are the general characteristics of
complex systems consisting of autonomous entities? What types of behavior
can a single or a collection of autonomous entities exhibit or generate? How
can we give a definition of autonomy based on the notion of behavior? In a
bottom-up computing system, how can the property of autonomy be modeled
and utilized? What types of problem is such a bottom-up computing paradigm
indented to solve? How different is this AOC paradigm from other previous or
current computing paradigms?",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4274899,"Jiming Liu, Xiaolong Jin and Kwok Ching Tsui","Book Series Multiagent Systems, Artificial Societies, and Simulated Organizations,  Volume 12, Book Autonomy Oriented Computing, Pages 3-14, SpringerLink Date Sunday, July 02, 2006",0
History and literature review,,1959,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6446008,Can't see authors,"Book Series Lecture Notes in Computer Science, Volume 42/1976, Book Complementary Definitions of Programming Language Semantics, Pages 5-21, SpringerLink Date Monday, April 10, 2006",0
How Artificial Intelligent Agents Do Shopping in a Virtual Mall: A ?Believable? and ?Usable? Multiagent-Based Simulation of Customers? Shopping Behavior in a Mall,"<p>Our literature review revealed that several applications successfully simulate certain kinds of human behaviors in spatial environments, but they have some limitations related to the &#8216;believability&#39; and the &#8216;usability&#39; of the simulations. This paper aims to present a set of requirements for multiagentbased simulations in terms of &#8216;believability&#39; and &#8216;usability&#39;. It also presents how these requirements have been put into use to develop a multiagent-based simulation prototype of customers&#39; shopping behavior in a mall. Using software agents equipped with spatial and cognitive capabilities, this prototype can be considered sufficiently &#8216;believable&#39; and &#8216;usable&#39; for end-users, mainly mall managers in our case. We show how shopping behavior simulator can support the decision-making process with respect to the spatial configuration of the shopping mall.</p>",2006,http://dl.acm.org/citation.cfm?id=2171217&CFID=932216256&CFTOKEN=53517999,Walid Ali and Bernard Moulin,"Book Series Lecture Notes in Computer Science, Volume 4013/2006, Book Advances in Artificial Intelligence, Pages 73-85, SpringerLink Date Wednesday, May 31, 2006",0
Implementing requirements engineering processes throughout organizations: success factors and challenges,"This paper aims at identifying critical factors affecting organization-wide implementation of requirements engineering (RE) processes. The paper is based on a broad literature review and three longitudinal case studies that were carried out using an action research method. The results indicate that RE process implementation is a demanding undertaking, and its success greatly depends on such human factors as motivation, commitment and enthusiasm. Therefore, it is essential that the RE process is useful for its individual users. Furthermore, the results indicate that organizations can gain benefits from RE by defining a simple RE process, by focusing on a small set of RE practices, and by supporting the systematic usage of these practices.",2004,http://www.sciencedirect.com/science/article/pii/S0950584904000692,"Marjo Kauppinena,*, Matti Vartiainenb, Jyrki Kontioa, Sari Kujalaa, Reijo Sulonena","Information and Software Technology, 46 (14), 937-953.",0
Integrating XML and Relational Database Systems,"Relational databases get more and more employed in order to store the content of a web site. At the same time, XML is fast emerging as the dominant standard at the hypertext level of web site management describing pages and links between them. Thus, the integration of XML with relational database systems to enable the storage, retrieval, and update of XML documents is of major importance. Data model heterogeneity and schema heterogeneity, however, make this a challenging task. In this respect, the contribution of this paper is threefold. First, a comparison of concepts available in XML schema specification languages and relational database systems is provided. Second, basic kinds of mappings between XML concepts and relational concepts are presented and reasonable mappings in terms of mapping patterns are determined. Third, design alternatives for integrating XML and relational database systems are examined and X-Ray, a generic approach for integrating XML with relational database systems is proposed. Finally, an in-depth evaluation of related approaches illustrates the current state of the art with respect to the design goals of X-Ray.",1996,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=539584,"Gerti Kappel, Elisabeth Kapsammer, Werner Retschitzegger","World Wide Web,   Volume 7 Issue 4, December 2004, Publisher: Kluwer Academic Publishers",0
Investigating the Role of Trust in Agile Methods Using a Light Weight Systematic Literature Review,"Abstract In this paper we use a cut down systematic literature review to investigate the role of trust in agile methods. Our main motivation is to investigate the impact of the enhanced role of developers in agile methods. It is important to investigate the role of trust in agile methods because according to the agile manifesto the role of individual developers is central in an agile team: Individuals and Interactions over processes and tools and Build projects around motivated individuals. Give them the environment and support they need, and trust them to get the job done [1]. This suggests that managers must trust their staff to make decisions. The most direct forum for trust in agile projects is in the daily stand-up meeting. Project managers must trust that what developers say in the standup they are going to achieve during the day is what they actually achieve. In this paper we investigate the role trust plays in agile methods.",2008,http://dx.doi.org/10.1007/978-3-540-68255-4_22,Eisha Hasnain and Tracy Hall,"Book Series Lecture Notes in Business Information Processing, Volume 9, Book Agile Processes in Software Engineering and Extreme Programming, Pages 204-207, SpringerLink Date Tuesday, June 10, 2008",0
Looking Back and Looking Forward: Diffusion and Adoption of Information Technology Research in IFIP WG 8.6?Achievements and Future Challenges,"Working Group 8.6 has existed for more than 10 years now. During this period, members
have continuously challenged the work of the group. Recently, researchers at the Copenhagen
Business Schcol conducted an interim review of the group's work in the fonn of a literature
analysis of all WG 8.6 conference contributions. That review concludes that WG 8.6 works 
toward and within its own aim and scope declaration, but that there are a number of challenges.
One is that WG 8.6 has no joint tenn~nology and no shared theoretical basis. One recommendation
from the review team. therefore. was that beyond researching new technologies like
mobile mforniation system and management fashions and fads such as business agility, WG 8.6
should stay with its roots and do work to explicitly contribute to IT diffusion theory and
terminology. On the basis of this interim rewew. a group of founding, regular. less-regular, and
more-recent members of WG 8.6 take a brief look back and a more extended look forward to
discuss the achievements and the future challenges of WG 8.6",2005,http://dx.doi.org/10.1007/0-387-25590-7_23,"Amadou Sienou, Elyes Lamine, Achim Karduck and Herv? Pingaud","Book Series Lecture Notes in Computer Science, Volume 4832/2007, Book Web Information Systems Engineering ? WISE 2007 Workshops, Pages 118-129, SpringerLink Date Thursday, November 22, 2007",0
MDE for BPM: A Systematic Review,"Due to the rapid change in the business processes of organizations, Business Process Management (BPM) has come into being. BPM helps business analysts to manage all concerns related to business processes, but the gap between these analysts and people who build the applications is still large. The organization’s value chain changes very rapidly; to modify simultaneously the systems that support the business management process is impossible. MDE (Model Driven Engineering) is a good support for transferring these business process changes to the systems that implement these processes. Thus, by using any MDE approach, such as MDA, the alignment between business people and software engineering should be improved. To discover the different proposals that exist in this area, a systematic review was performed. As a result, the OMG’s Business Process Definition Metamodel (BPDM) has been identified as the standard that will be the key for the application of MDA for BPM.",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7226855,"Jose Manuel Perez, Francisco Ruiz and Mario Piattini","Book Series Communications in Computer and Information Science, Volume 10, Book Software and Data Technologies, Part 3, Pages 127-135, SpringerLink Date Friday, July 18, 2008",0
Measuring Effective Data Visualization,"In this paper, we systematically examine two fundamental questions in information visualization – how to define effective visualization and how to measure it. Through a literature review, we point out that the existing definitions of effectiveness are incomplete and often inconsistent – a problem that has deeply affected the design and evaluation of visualization. There is also a lack of standards for measuring the effectiveness of visualization as well as a lack of standardized procedures. We have identified a set of basic research issues that must be addressed. Finally, we provide a more comprehensive definition of effective visualization and discuss a set of quantitative and qualitative measures. The work presented in this paper contributes to the foundational research of information visualization.",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4026964,Ying Zhu,"Book Series Lecture Notes in Computer Science, Volume 4842/2007, Book Advances in Visual Computing, Pages 652-661, SpringerLink Date Thursday, November 22, 2007",0
Motivation in Software Engineering: A systematic literature review,"Objective
In this paper, we present a systematic literature review of motivation in Software Engineering. The objective of this review is to plot the landscape of current reported knowledge in terms of what motivates developers, what de-motivates them and how existing models address motivation.

Methods
We perform a systematic literature review of peer reviewed published studies that focus on motivation in Software Engineering. Systematic reviews are well established in medical research and are used to systematically analyse the literature addressing specific research questions.

Results
We found 92 papers related to motivation in Software Engineering. Fifty-six percent of the studies reported that Software Engineers are distinguishable from other occupational groups. Our findings suggest that Software Engineers are likely to be motivated according to three related factors: their ‘characteristics’ (for example, their need for variety); internal ‘controls’ (for example, their personality) and external ‘moderators’ (for example, their career stage). The literature indicates that de-motivated engineers may leave the organisation or take more sick-leave, while motivated engineers will increase their productivity and remain longer in the organisation. Aspects of the job that motivate Software Engineers include problem solving, working to benefit others and technical challenge. Our key finding is that the published models of motivation in Software Engineering are disparate and do not reflect the complex needs of Software Engineers in their career stages, cultural and environmental settings.

Conclusions
The literature on motivation in Software Engineering presents a conflicting and partial picture of the area. It is clear that motivation is context dependent and varies from one engineer to another. The most commonly cited motivator is the job itself, yet we found very little work on what it is about that job that Software Engineers find motivating. Furthermore, surveys are often aimed at how Software Engineers feel about ‘the organisation’, rather than ‘the profession’. Although models of motivation in Software Engineering are reported in the literature, they do not account for the changing roles and environment in which Software Engineers operate. Overall, our findings indicate that there is no clear understanding of the Software Engineers’ job, what motivates Software Engineers, how they are motivated, or the outcome and benefits of motivating Software Engineers.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6915266,"Sarah Beecham, Nathan Baddoo, Tracy Hall, Hugh Robinson, Helen Sharp","Information and Software Technology,   Volume 50 Issue 9-10, August 2008 , Publisher: Butterworth-Heinemann",0
Postmortem reviews: purpose and approaches in software engineering.,"Conducting postmortems is a simple and practical method for organisational learning. Yet, not many companies have implemented such practices, and in a survey, few expressed satisfaction with how postmortems were conducted. In this article, we discuss the importance of postmortem reviews as a method for knowledge sharing in software projects, and give an overview of known such processes in the field of software engineering. In particular, we present three lightweight methods for conducting postmortems found in the literature, and discuss what criteria companies should use in defining their way of conducting postmortems.",2003,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1207473,T. Dingsoyr.,"Information and Software Technology 47 (5):293-303, 2005.",0
Process Design Theory for Digital Information Services,"Information services transfer information goods from a creator to a user. Information services have three design aspects, i. e. content, value, and revenue, and their design has an evolutionary nature, i. e. that information gained in the service’s usage stages is part of their (re)design efforts. The literature abounds of fragmented insights for information services design. This article gives a literature review of methods and techniques that are useful in the representation and analysis of the above-mentioned aspects for each evolving step of information service design. The article also describes several scenarios for information service design projects. These insights have considerable consequences for information services design practices and a list of topics for new design theory research is given.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5496363,Fons Wijnhoven,"Book Methods and Tools for Effective Knowledge Life-Cycle-Management, Part Part 3, Pages 533-546, SpringerLink Date Tuesday, April 01, 2008",0
Refactoring test suites versus test behaviour: a TTCN-3 perspective,"As a software engineering discipline, refactoring offers the opportunity for reversal of software 'decay' and preservation of a level of software quality. In a recent paper by Zeiss et al. [23], a set of fifteen refactorings were found applicable to Testing and Test Control Notation (TTCN-3) test behaviour and a set of thirteen refactorings to improving the overall structure of a TTCN-3 test suite. All twenty-eight refactorings were taken from the set of seventy-two described in the seminal text by Fowler [10]. An important issue with any refactoring is the testing effort required during implementation of its mechanics. In this paper, we explore the trade-offs between, and the contrasting characteristics of, the two TTCN-3 sets of refactorings from a refactoring mechanics perspective. Firstly, we use a meta-analysis of the same twenty-eight refactorings based on a dependency matrix developed through scrutiny of the mechanics of all seventy-two refactorings in [10] and then an analysis of the refactoring chains emerging from each of the same twenty-eight refactorings. Results suggest that there are compelling reasons for avoiding test suite structure refactorings when the dependencies and chains of the test suite refactorings are considered. Refactoring test behaviour potentially offers a far simpler, less demanding set of tasks required of the developer both from a re-testing and dependency viewpoint.",2007,http://dl.acm.org/citation.cfm?id=1295081&CFID=932211031&CFTOKEN=62642147,"Steve Counsell, Rob M. Hierons","SOQUA '07: Fourth international workshop on Software quality assurance: in conjunction with the 6th ESEC/FSE joint meeting, September 2007, Publisher: ACM",0
Reporting Experiments in Software Engineering,"One major problem for integrating study results into a common body of knowledge is the heterogeneity of reporting styles: (1) it is difficult to locate relevant information and (2) important information is often missing. Reporting guidelines are expected to support a systematic, standardized presentation of empirical research, thus improving reporting in order to support readers in (1) finding the information they are looking for, (2) understanding how an experiment is conducted, and (3) assessing the validity of its results. The objective of this paper is to survey the most prominent published proposals for reporting guidelines, and to derive a unified standard that which can serve as a starting point for further discussion. We provide detailed guidance on the expected content of the sections and subsections for reporting a specific type of empirical studies, i.e., controlled experiments. Before the guidelines can be evaluated, feedback from the research community is required. For this purpose, we propose to adapt guideline development processes from other disciplines.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1541818,"Andreas Jedlitschka, Marcus Ciolkowski and Dietmar Pfahl","Book Guide to Advanced Empirical Software Engineering, Publisher Springer London, DOI 10.1007/978-1-84800-044-5, ISBN 978-1-84800-043-8 (Print) 978-1-84800-044-5 (Online), Part Section II, Pages 201-228, SpringerLink Date Wednesday, November 21, 2007",0
Requirements Analysis: A Review,"Many software organizations often bypass the requirements analysis phase of the software development life cycle process and skip directly to the implementation phase in an effort to save time and money. The results of such an approach often leads to projects not meeting the expected deadline, exceeding budget, and not meeting user needs or expectations. One of the primary benefits of requirements analysis is to catch problems early and Minimize thier impact with respect to time and money. This paper is a literature review of the requirements analysis phase and the multitude of techniques available to perform the analysis. It is hoped that by compiling the information into a single document, readers will be more in a position to understand the requirements engineering process and provide analysts a compelling argument as to why it should be employed in modern day software development. ",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7416336,Joseph Catanio,"Book Advances in Systems, Computing Sciences and Software Engineering,Pages 411-418,SpringerLink Date Thursday, September 27, 2007",0
Requirements of Software Visualization Tools: A Literature Survey,"Our objective is to identify requirements (i.e., quality attributes and functional requirements) for software visualization tools. We especially focus on requirements for research tools that target the domains of visualization for software maintenance, reengineering, and reverse engineering. The requirements are identified with a comprehensive literature survey based on relevant publications in journals, conference proceedings, and theses. The literature survey has identified seven quality attributes (i.e., rendering scalability, information scalability, interoperability, customizability, interactivity, usability, and adoptability) and seven functional requirements (i.e., views, abstraction, search, filters, code proximity, automatic layouts, and undo/history). The identified requirements are useful for researchers in the software visualization field to build and evaluate tools, and to reason about the domain of software visualization.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4290693,"By Holger M. Kienle , Hausi A. Muller","Found in: 2007 4th IEEE International Workshop on Visualizing Software for Understanding and Analysis 
Issue Date:June 2007 
pp. 2-9",0
Research Directions in Requirements Engineering,"In this paper, we review current requirements engineering (RE) research and identify future research directions suggested by emerging software needs. First, we overview the state of the art in RE research. The research is considered with respect to technologies developed to address specific requirements tasks, such as elicitation, modeling, and analysis. Such a review enables us to identify mature areas of research, as well as areas that warrant further investigation. Next, we review several strategies for performing and extending RE research results, to help delineate the scope of future research directions. Finally, we highlight what we consider to be the ""hot"" current and future research topics, which aim to address RE needs for emerging systems of the future.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4221627,"Betty H. C. Cheng, Joanne M. Atlee","FOSE '07: 2007 Future of Software Engineering, May 2007, Publisher: IEEE Computer Society",0
Review article: A review of structured document retrieval (SDR) technology to improve information access performance in engineering document management,"Information retrieval (IR) is a well-established research and development area. Document formats such as SGML (Standard Generalised Mark-up Language) and XML (eXtensible Mark-up Language) have become widely used in recent years. Traditional IR systems demonstrate limitations when dealing with such documents, which motivated the emergence of structured document retrieval (SDR) technology intending to overcome these limitations. This paper reviews the work carried out from the inception to the development and application of SDR in engineering document management. The key issues of SDR are discussed and the state of the art of SDR to improve information access performance has been surveyed. A comparison of selected papers is provided and possible future research directions identified. The paper concludes with the expectation that SDR will make a positive impact on the process of engineering document management from document construction to its delivery in the future, and undoubtedly provide better information retrieval performance in terms of both precision and functionality.",2008,http://dl.acm.org/citation.cfm?id=1322618&CFID=932222138&CFTOKEN=29731326,"S. Liu, C. A. McMahon, S. J. Culley","Computers in Industry,   Volume 59 Issue 1 , January 2008 , Publisher: Elsevier Science Publishers B. V.",0
Role of annotation in Electronic Process Guide,Annotations play a major part in our daily life. Similarly electronic process guide or EPG plays an important role in software development in an organization. An EPG can guide the developers about the process used or followed in an environment. The paper describes the annotation in electronic process guide for developers. We first introduced the background of the topic and some of the related researched done in the area of annotation systems. Some of the annotation systems for the Web are available either free or commercially. We then focus on the literature survey on the use of annotation tools and technique in different areas along with the usage of EPG in different scenarios. We also focus on Web based annotation for Jasmine EPG and conclusion is given with the future work.,2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4426306,"Ibrahim, A., Choi, H.-J.","(2007) Proceedings of Future Generation Communication and Networking, FGCN 2007, 1, art. no. 4426306, pp. 569-572.",0
SArt: Towards Innovation at the intersection of Software engineering and art,"Abstract Computer science and art have been in contact since the 1960s. Our hypothesis is that software engineering can benefit from multidisciplinary research at the intersection with art for the purpose of increasing innovation and creativity. To do so, we have designed and planned a literature review in order to identify the existing knowledge base in this interdisciplinary field. A preliminary analysis of both results of our review and observations of software development projects with artist participation, reveals four main issues. These are software development issues, which include requirement management, tools, development and business models; educational issues, with focus on multidisciplinary education; aesthetics of both code and user interface, and social and cultural implications of software and art. The identified issues and associated literature should help researchers design research projects at the intersection of software engineering and art. Moreover, they should help artists to increase awareness about software engineering methods and tools when conceiving and implementing their software-based artworks.",2009,http://dx.doi.org/10.1007/978-0-387-78578-3_17,"Anna Trifonova, Salah U. Ahmed, Letizia Jaccheri",? 2007 ? Proceedings of The 16th International Conference on Information Systems Development,0
Scenario-Based Application Requirements Engineering,"In product line engineering, the application requirements engineers have to ensure both a
high degree of reuse and the satisfaction of stakeholder needs. The vast number of possible
variant combinations and the influences of the selection of one variant on different requirements
models is a challenge for the consistent reuse of product line requirements. Only if the
requirements engineers are aware of all product line capabilities (variabilities and commonalities),
they are able to decide whether a stakeholder requirement can be satisfied by the
product line or not. In this chapter we present a novel approach for the development of application
requirements specifications. For this approach, we use an orthogonal variability
model with associated requirements scenarios to support requirements engineers during the
elicitation, negotiation, documentation, and validation of product line requirements. The
presented approach tackles the existing challenges during application requirements engineering by the iterative use of the orthogonal variability model (abstract view) and the requirements scenarios (concrete view) of the product line.",2012,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6170926,"Stan Bhne, Gnter Halmans, Kim Lauenroth and Klaus Pohl","Book Software Product Lines, Part 2, Pages 161-194,SpringerLink Date Wednesday, February 07, 2007",0
Software Architecture Visualization: An Evaluation Framework and Its Application,"In order to characterize and improve software architecture visualization practice, the paper derives and constructs a qualitative framework, with seven key areas and 31 features, for the assessment of software architecture visualization tools. The framework is derived by the application of the Goal Question Metric paradigm to information obtained from a literature survey and addresses a number of stakeholder issues. The evaluation is performed from multiple stakeholder perspectives and in various architectural contexts. Stakeholders can apply the framework to determine if a particular software architecture visualization tool is appropriate to a given task. The framework is applied in the evaluation of a collection of six software architecture visualization tools. The framework may also be used as a design template for a comprehensive software architecture visualization tool.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4378398,"By Keith Gallagher , Andrew Hatch , Malcolm Munro","Found in: IEEE Transactions on Software Engineering 
Issue Date:March 2008 
pp. 260-270",0
Software Components Evaluation: an Overview,"Objective: To contribute with an overview on the current state of the art concerning
metrics-based quality evaluation of software components and component-based assemblies.
Method: Comparison of several approaches available in the literature, in terms of their
scope, intent, definition technique and maturity.
Results: Common shortcomings of current approaches, such as ambiguity in definition,
lack of adequacy of the specifying formalisms and insufficient validation of current quality
models and metrics for software components.
Conclusions: Quality evaluation of components and component-based infrastructures
presents new challenges to the Experimental Software Engineering community which are
not conveniently dealt with by current approaches.
Keywords: Component-Based Software Engineering; Component Evaluation; Software
Metrics; Software Quality.",2011,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5974788,"M Goul?o, F B Abreu",In Proceedings of the 5? Confer?ncia da APSI,0
Software Multi-project Resource Scheduling: A Comparative Analysis,"Software organizations are always multi-project-oriented, in which situation the traditional project management for individual project is not enough. Related scientific research on multi-project is yet scarce. This paper reports result from a literature review aiming to organize, analyze and make sense out of the dispersed field of multi-project resource scheduling methods. A comparative analysis was conducted according to 6 aspects of application situations: value orientation, centralization, homogeneity, complexity, uncertainty and executive ability. The findings show that, traditional scheduling methods from general project management community have high degree of centralization and limited capability to deal with uncertainty, and do not well catered for software projects. In regard to these aspects agile methods are better, but most of them lack scalability to high complexity. Some methods have balanced competence and special attention should be paid to them. In brief, methods should be chosen according to different situations in practice.",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7152569,"Fei Dong, Mingshu Li, Yuzhu Zhao, Juan Li and Ye Yang","Book Series Lecture Notes in Computer Science,  Volume 5007/2008, Book Making Globally Distributed Software Development a Success Story, Pages 63-75, SpringerLink Date Tuesday, May 06, 2008",0
Software Reliability Management: Techniques and Applications,"In this chapter we discuss three new stochastic
models for assessing software reliability and the
degree of software testing progress, and a software
reliability management tool.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1513236,Mitsuhiro Kimura and Shigeru Yamada,"Book Handbook of Reliability Engineering, Part Part III, Pages 265-284, SpringerLink Date Tuesday, April 18, 2006",0
Software Reliability Models: A Selective Survey and New Directions,"Software development, design, and testing have
become very intricate with the advent of modern
highly distributed systems, networks, middleware,
and interdependent applications. The demand for
complex software systems has increased more
rapidly than the ability to design, implement, test,
and maintain them, and the reliability of software
systems has become a major concern for our
modern society. Within the last decade of the 20th
century and the first few years of the 21st century,
many reported system outages or machine crashes
were traced back to computer software failures.
Consequently, recent literature is replete with
horror stories due to software problems.",2003,http://dx.doi.org/10.1007/1-85233-841-5_11,Siddhartha Dalal,"Handbook of Reliability Engineering, Publisher Springer London, Pages 201-211",0
Special Characteristics of Software and Software Markets - Implications for Managing Software Business,"This paper examines software markets, and especially how market effects affect how value is created and captured. We propose an initial model that incorporates both the special effects related to software markets, how these effects affect value of software and what factors should be considered to leverage the effects. The model is based on a literature review that resulted in identifying four specific market effects: network externalities, returns to complements, lock-in, and positive feedback. Furthermore, we identified four issues the firms should consider when pursuing the desired market effects: market definition, value configuration, contracts and legal actions, and customers. The literature-based model was evaluated and complemented by two case studies with Finnish software firms incorporating altogether 17 interviews. The model gained initial support on the basis of the interviews. This paper proposes that the identified market effects should be considered when the value of software engineering decisions is evaluated",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1690152,"Mikko Ronkko, Paivi Poyry","EUROMICRO '06: Proceedings of the 32nd EUROMICRO Conference on Software Engineering and Advanced Applications , August 2006 , Publisher: IEEE Computer Society",0
Supporting software development with roles.,"Software development tools are very important in software engineering. Although roles have been acknowledged and applied for many years in several areas related to software engineering, there is a lack of research on software development tools based on roles. Most significantly, there is no complete and consistent consideration of roles in all the phases of software development. Considering the increasing importance and applications of roles in software development, this paper intends to discuss the importance of roles in software engineering and that of role-based software development; review the literature relevant to role mechanisms in software engineering; propose and describe a role-based software process; and implement a prototype tool for developing complex software systems with the help of role mechanisms",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1715481,"H. B. Zhu, M. C. Zhou, and P. Seguin.","Ieee Transactions on Systems Man and Cybernetics Part A-Systems and Humans 36 (6):1110-1123, 2006.",0
Supporting the selection of model-based testing approaches for software projects,"Software technologies, such as model-based testing approaches, have specific characteristics and limitations that can affect their use in software projects. To make available knowledge regarding such technologies is important to support the decision regarding their use in software projects. In particular, a choice of model-based testing approach can influence testing success or failure. Therefore, this paper aims at describing knowledge acquired from a systematic review regarding model-based testing approaches and proposing an infrastructure towards supporting their selection for software projects.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5457788,"Arilo Claudio Dias Neto, Guilherme Horta Travassos","AST '08: Proceedings of the 3rd international workshop on Automation of software test , May 2008 , Publisher: ACM",0
Ten Strategies for Successful Distributed Development,"This paper presents an overview of the field of distributed development of software systems and applications (DD). Based on an analysis of the published literature, including its use in different industrial contexts, we provide a preliminary analysis that structures existing DD knowledge, indicating opportunities but identifying threats to communication, coordination, and control caused by temporal distance, geographical distance, and socio-cultural distance. An analysis of the case and field study literature has been used to identify strategies considered effective for countering the identified threats. The paper synthesizes from these a set of 10 general strategies for successful DD which, if adopted, should lead to increased company resilience.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7058642,"Brian Lings, Bj?rn Lundell, P?r J. gerfalk and Brian Fitzgerald","Book Series IFIP International Federation for Information Processing, Volume 206/2006, Book The Transfer and Diffusion of Information Technology for Organizational Resilience, Pages 119-137, SpringerLink Date Thursday, August 17, 2006",0
The affordable application of formal methods to software engineering,"The purpose of this research paper is to examine (1) why formal methods are required for software systems today; (2) the Praxis High Integrity Systems' Correctness-by-Construction methodology; and (3) an affordable application of a formal methods methodology to software engineering. The cultivated research for this paper included literature reviews of documents found across the Internet and in publications as well as reviews of conference proceedings including the 2004 High Confidence Software and Systems Conference and the 2004 Special Interest Group on Ada Conference. This research realized that (1) our reliance on software systems for national, business and personal critical processes outweighs the trust we have in our systems; (2) there is a growing demand for the ability to trust our software systems; (3) methodologies such as Praxis' Correctness-by-Construction are readily available and can provide this needed level of trust; (4) tools such as Praxis' SparkAda when appropriately applied can be an affordable approach to applying formal methods to a software system development process; (5) software users have a responsibility to demand correctness; and finally, (6) software engineers have the responsibility to provide this correctness. Further research is necessary to determine what other methodologies and tools are available to provide affordable approaches to applying formal methods to software engineering. In conclusion, formal methods provide an unprecedented ability to build trust in the correctness of a system or component. Through the development of methodologies such as Praxis' Correctness by Construction and tools such as SparkAda, it is becoming ever more cost advantageous to implement formal methods within the software engineering lifecycle. As the criticality of our IT systems continues to steadily increase, so must our trust that these systems will perform as expected. Software system clients, such as government, businesses and all other IT users, must demand that their IT systems be delivered with a proven level of correctness or trust commensurate to the criticality of the function they perform.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6913383,By James F. Davis,"Found in: Proceedings of the 2005 annual ACM SIGAda international conference on Ada: The Engineering of Correct and Reliable Software for Real-Time & Distributed Systems using Ada and Related Technologies (SigAda '05) , Issue Date:November 2005 , pp. 2266-2271",0
"The Brave New World of Ambient Intelligence: An Analysis of Scenarios Regarding Privacy, Identity and Security Issues","<p>The success of Ambient Intelligence (AmI) will depend on how secure it can be made, how privacy and other rights of individuals can be protected and how individuals can come to trust the intelligent world that surrounds them and through which they move. This contribution presents an analysis of ambient intelligence scenarios, particularly in regard to AmI&#39;s impacts on and implications for individual privacy. The analysis draws on our review of more than 70 AmI projects, principally in Europe. It notes the visions as well as the specifics of typical AmI scenarios. Several conclusions can be drawn from the analysis, not least of which is that most AmI scenarios depict a rather too sunny view of our technological future. Finally, reference is made to the SWAMI project (Safeguards in a World of Ambient Intelligence) which, inter alia, has constructed &#8221;dark&#8221; scenarios, as we term them, to show how things can go wrong in AmI and where safeguards are needed.</p>",2006,http://dl.acm.org/citation.cfm?id=2182216&CFID=932218515&CFTOKEN=38944624,"Michael Friedewald, Elena Vildjiounaite, Yves Punie and David Wright","Book Series Lecture Notes in Computer Science, Volume 3934/2006, Book Security in Pervasive Computing, Pages 119-133, SpringerLink Date Friday, March 10, 2006",0
The Clients? Impact on Effort Estimation Accuracy in Software Development Projects,"This paper focuses on the clients' impact on estimation accuracy in software development projects. Client related factors contributing to effort overruns as well as factors preventing overruns are investigated. Based on a literature review and a survey of 300 software professionals we find that: 1) software professionals perceive that clients impact estimation accuracy. Changed and new requirements are perceived as the clients' most frequent contribution to overruns, while overruns are prevented by the availability of competent clients and capable decision makers. 2) Survey results should not be used in estimation accuracy improvement initiatives without further analysis. Surveys typically identify directly observable and project specific causes for overruns, while substantial improvement is only possible when the underlying causes are understood",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1509288,"By Stein Grimstad , Magne Jorgensen , Kjetil Molokken-Ostvold","Found in: 11th IEEE International Software Metrics Symposium (METRICS'05) 
Issue Date:September 2005 , pp. 3",0
The design of participatory agent-based social simulations.,"It is becoming widely accepted that applied social simulation research is more effective if potential users and stakeholders are closely involved in model specification, design, testing and use, using the principles of participatory research. In this paper, a review of software engineering principles and accounts of the development of simulation models are used as the basis for recommendations about some useful techniques that can aid in the development of agent-based social simulation models in conjunction with users. The authors' experience with scenario analysis, joint analysis of design workshops, prototyping and user panels in a collaborative participatory project is described and, in combination with reviews from other participatory projects, is used to suggest how these techniques might be used in simulation-based research.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6576815,A. M. Ramanath and N. Gilbert.,"Jasss-the Journal of Artificial Societies and Social Simulation 7 (4), 2004.",0
The evolution of goal-based information modelling: Literature review,"Purpose
– The first in a series on goal?based information modelling, this paper presents a literature review of two goal?based measurement methods. The second article in the series will build on this background to present an overview of some recent case?based research that shows the applicability of the goal?based methods for information modelling (as opposed to measurement). The third and concluding article in the series will present a new goal?based information model – the goal?based information framework (GbIF) – that is well suited to the task of documenting and evaluating organisational information flow.

Design/methodology/approach
– Following a literature review of the goal?question?metric (GQM) and goal?question?indicator?measure (GQIM) methods, the paper presents the strengths and weaknesses of goal?based approaches.

Findings
– The literature indicates that the goal?based methods are both rigorous and adaptable. With over 20 years of use, goal?based methods have achieved demonstrable and quantifiable results in both practitioner and academic studies. The down side of the methods are the potential expense and the “expansiveness” of goal?based models. The overheads of managing the goal?based process, from early negotiations on objectives and goals to maintaining the model (adding new goals, questions and indicators), could make the method unwieldy and expensive for organisations with limited resources. An additional challenge identified in the literature is the narrow focus of “top?down” (i.e. goal?based) methods. Since the methods limit the focus to a pre?defined set of goals and questions, the opportunity for discovery of new information is limited.

Research limitations/implications
– Much of the previous work on goal?based methodologies has been confined to software measurement contexts in larger organisations with well?established information gathering processes. Although the next part of the series presents goal?based methods outside of this native context, and within low maturity organisations, further work needs to be done to understand the applicability of these methods in the information science discipline.

Originality/value
– This paper presents an overview of goal?based methods. The next article in the series will present the method outside the native context of software measurement. With the universality of the method established, information scientists will have a new tool to evaluate and document organisational information flow.",2011,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5917980,"Boyd, A.J.","(2005) Aslib Proceedings: New Information Perspectives, 57 (6), pp. 523-538.",0
The Golden Age of Software Architecture: A Comprehensive Survey,"This retrospective on nearly two decades of software architecture research examines the maturation of the software architecture research area by tracing the evolution of research questions and results through their maturation cycle. We show how early qualitative results set the stage for later precision, formality, and automation, how results have built up over time, and how the research results have moved into practice.",2009,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5076462,Mary Shaw and Paul Clements,"Published in IEEE Software, March/April 2006 [79].",0
The Need for a Paradigm Shift in Addressing Privacy Risks in Social Networking Applications,"Abstract New developments on the Internet in the past years have brought up a number of online social networking applications within the so-called Web 2.0 world that experienced phenomenal growth and a tremendous attention in the public. Online social networking services build their business model on the myriad of sensitive personal data provided freely by their users, a fact that is increasingly getting the attention of privacy advocates. After explaining the economic meaning and importance of online social networks to eCommerce in general and reiterating the basic principles of Web 2.0 environments and their enterprise mechanisms in particular, this paper addresses the main informational privacy risks of Web 2.0 business models with a focus on online social networking sites. From literature review and current expert discussions, new privacy research questions are proposed for the future development of privacyenhancing technologies used within Web 2.0 environments. The resulting paradigm shift needed in addressing privacy risks in social networking applications is likely to focus less on access protection, anonymity and unlinkability type of PET-solutions and more on privacy safeguarding measures that enable greater transparency and that directly attach context and purpose limitation to the personally identifiable data itself. The FIDIS/IFIP workshop discussion has resulted in the idea to combine existing privacy-enhancing technologies and protection methods with new safeguarding measures to accommodate the Web 2.0 dynamics and to enhance the informational privacy of Web 2.0 users.",2008,http://dx.doi.org/10.1007/978-0-387-79026-8_12,Stefan Weiss,,0
Tightening knowledge sharing in distributed software communities by applying semantic technologies,This report describes the state of the research and practice in the areas of Knowledge Management in Software Engineering. Special emphasis is laid upon specific knowledge representation and reasoning requirements coming from the open-source communities and outsourced software development,2009,https://cordis.europa.eu/pub/ist/docs/directorate_d/st-ds/team-project-story_en.pdf,"Spyros Ntioudis, Walid Maalej, Hans-Joerg Happel, Dimitris Panagiotou","Information Society Technologies (IST) 
September 1st, 2006",0
Tool integration in software engineering: The state of the art in 2004,"The aim of this paper is to identify and investigate previous research in the area of software engineering environments, and how tools are integrated to form such a facility, with the goal of identifying future research questions. The paper consists of an explanation of the method used to identify papers, with each placed in a candidate category. Each of the seven categories is examined in turn, with each paper in each category then reviewed, with any possible arising research questions identified by the author of this paper included. Also included in this review is a section that discusses additional material being papers that have been referenced more than once. The paper concludes by making summing up all the suggestions for further research that were identified in the reviewing of particular papers. Full references and a glossary of commonly used terms completes the paper.",2004,http://www.macs.hw.ac.uk/cs/techreps/docs/files/HW-MACS-TR-0021.pdf,Mike Wicks,Can't see source,0
Towards management of software as assets: A literature review with additional sources.,"How should and how can software be managed? What is the management concept or paradigm? Software professionals, if they think about management of software at all, think in terms of Configuration Management. This is not a method for over-all software management; it merely controls software items' versions. This is much too fine a level of granularity. Management begins with accurate and timely information. Managers tend to view software as something (unfortunately) very necessary but troubling because, they have very little real information about it and control is still nebulous, at best. Accountants view software as an incomprehensible intangible, neither wholly an expense nor really an asset. They do not have, nor do they produce information concerning it. Their data concerning software barely touches on direct outlays and contains no element of effort. Part of this disorientation is the basic confusion between ''business software'' and ''engineering software''. This ''Gordian Knot'' must be opened; it needs to be made much more clear. This article shows a direction how such clarity may be achieved.",2008,http://dl.acm.org/citation.cfm?id=1331079&CFID=932221793&CFTOKEN=69891793,M. Ben-Menachem.,"Information and Software Technology 50 (4):241-258, 2008.",0
Transformational Approaches to Model Driven Architecture - A Review,"The model driven architecture (MDA) has been widely used as a paradigm in software development. This paper presents an overview on the current research in the model driven architecture. We analyze the key concepts of the MDA by illustrative examples, explore the existing approaches and tools that support model transformation - the essential part of the MDA, and classify these methods based on a multidimensional scheme. Furthermore, this paper summarizes the current technical achievements of model transformation techniques in software development at different abstraction levels of a system.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4402766,"By Chunying Zhao , Kang Zhang","Found in: 31st IEEE Software Engineering Workshop (SEW 2007) 
Issue Date:March 2007 
pp. 67-74",0
Troubleshooting large-scale new product development embedded software projects,"<p>Many modern new product development (NPD) embedded software projects are required to be run under turbulent conditions. Both the business and the technological environments are often volatile. Uncertainty is then an inherent part of the project management. In such cases, traditional detailed up-front planning with supporting risk management is often inadequate, and more adaptive project management tools are needed. This industrial paper investigates the typical problem space of those embedded software projects. Based on a literature survey coupled with our practical experiences, we compose an extensive structured matrix of different potential project problem factors, and propose a method for assessing the project&#39;s problem profile with the matrix. The project manager can then utilize that information for problem-conscious project management. Some industrial case examples of telecommunications products embedded software development are illustrated.</p>",2006,http://dl.acm.org/citation.cfm?id=2094565&CFID=932215594&CFTOKEN=34436793,"Kettunen, P.","(2006) Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), 4034 LNCS, pp. 61-78.",0
What Architects Should Know About Reverse Engineering and Rengineering,"Architecture reconstruction is a form of reverse engineering that reconstructs architectural views from an existing system. It is often necessary because a complete and authentic architectural description is not available. This paper puts forward the goals of architecture reconstruction, revisits the technical difficulties we are facing in architecture reconstruction, and presents a summary of a literature survey about the types of architectural viewpoints addressed in reverse engineering research.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1620085,By Rainer Koschke,"Found in: Fifth Working IEEE/IFIP Conference on Software Architecture (WICSA'05) 
Issue Date:November 2005 
pp. 4-10",0
A Comparison of Software Project Overruns-Flexible versus Sequential Development Models,"Flexible software development models, e.g., evolutionary and incremental models, have become increasingly popular. Advocates claim that among the benefits of using these models is reduced overruns, which is one of the main challenges of software project management. This paper describes an in-depth survey of software development projects. The results support the claim that projects which employ a flexible development model experience less effort overruns than do those which employ a sequential model. The reason for the difference is not obvious. We found, for example, no variation in project size, estimation process, or delivered proportion of planned functionality between projects applying different types of development model. When the managers were asked to provide reasons for software overruns and/or estimation accuracy, the largest difference was that more of flexible projects than sequential projects cited good requirement specifications-and good collaboration/communication with clients as contributing to accurate estimates.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1514444,"By Kjetil Molokken-Ostvold , Magne Jorgensen","Found in: IEEE Transactions on Software Engineering 
Issue Date:September 2005 
pp. 754-766",0
A meta-analysis of the technology acceptance model,"The paper will address issues related to 3D capture, documentation, storage and management of virtual replicas of museum objects for documentation purposes in view of their inclusion in Europeana. 3D cultural objects present a number of challenges concerning their management. The 3D-COFORM project will provide solutions aiming at making 3D documentation a common practice in the cultural heritage sector. This requires the definition of good practices for data acquisition and storage, together with the design of a novel documentation system for the acquisition and simplification procedures. In fact, these initial steps are often undocumented, and this makes the outcome unreliable for the strict criteria of heritage documentation. The following steps of storing, managing, searching and displaying 3D objects is still an uneasy process, and the project aims at providing state-of-the-art tools to improve the performance in all these stages. Finally, the project will address business processes, mainly through the design and start-up of a Virtual Competence Centre in order to provide guidance to cultural heritage institutions and practitioners wishing to incorporate 3D into their everyday practice.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5753008,"William R. King, Jun He","Information and Management,   Volume 43 Issue 6 ,September 2006 ,Publisher: Elsevier Science Publishers B. V.",0
A Probabilistic Model for Predicting Software Development Effort,"Recently, Bayesian probabilistic models have been used for predicting software development effort. One of the reasons for the interest in the use of Bayesian probabilistic models, when compared to traditional point forecast estimation models, is that Bayesian models provide tools for risk estimation and allow decision-makers to combine historical data with subjective expert estimates. In this paper, we use a Bayesian network model and illustrate how a belief updating procedure can be used to incorporate decision-making risks. We develop a causal model from the literature and, using a data set of 33 real-world software projects, we illustrate how decision-making risks can be incorporated in the Bayesian networks. We compare the predictive performance of the Bayesian model with popular nonparametric neural-network and regression tree forecasting models and show that the Bayesian model is a competitive model for forecasting software development effort.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1492375,"By Parag C. Pendharkar , Girish H. Subramanian , James A. Rodger","Found in: IEEE Transactions on Software Engineering 
Issue Date:July 2005 , pp. 615-624",0
A survey of literature on the teaching of introductory programming,"This paper reports the authors' experiences in teaching introductory programming for engineers in an interactive classroom.. The authors describe how the course has evolved from the traditional course, the structure of the classroom, the choice of software, and the elements involving interactive, active, and collaborative learning. They discuss their strategy for assessment. They describe the assessment results including a retrospective assessment of the previous course. They suggest how the course relates to the nontraditional student. They conclude with some suggestions for future modifications",2001,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=964019,"Arnold Pears, Stephen Seidman, Lauri Malmi, Linda Mannila, Elizabeth Adams, Jens Bennedsen, Marie Devlin, James Paterson","ITiCSE-WGR '07: Working group reports on ITiCSE on Innovation and technology in computer science education, December 2007, Publisher: ACM",0
"A Survey on Hair Modeling: Styling, Simulation, and Rendering","Realistic hair modeling is a fundamental part of creating virtual humans in computer graphics. This paper surveys the state of the art in the major topics of hair modeling: hairstyling, hair simulation, and hair rendering. Because of the difficult, often unsolved problems that arise in alt these areas, a broad diversity of approaches is used, each with strengths that make it appropriate for particular applications. We discuss each of these major topics in turn, presenting the unique challenges facing each area and describing solutions that have been presented over the years to handle these complex issues. Finally, we outline some of the remaining computational challenges in hair modeling",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4069232,"By Kelly Ward , Florence Bertails , Tae-Yong Kim , Stephen R. Marschner , Marie-Paule Cani , Ming C. Lin","Found in: IEEE Transactions on Visualization and Computer Graphics 
Issue Date:March 2007 , pp. 213-234",0
An assessment of systems and software engineering scholars and institutions (1999-2003),"This paper presents the findings of a five-year study of the top scholars and institutions in the Systems and Software Engineering field, as measured by the quantity of papers published in the journals of the field. The top scholar is Khaled El Emam of the Canadian National Research Council, and the top institution is Carnegie Mellon University and its Software Engineering Institute.

This paper is part of an ongoing study, conducted annually, that identifies the top 15 scholars and institutions in the most recent five-year period.",2004,http://www.sciencedirect.com/science/article/pii/S0164121204001414,"Robert L. Glass, T. Y. Chen","April 2005, Journal of Systems and Software,   Volume 76 Issue 1, Publisher: Elsevier Science Inc.",0
An Empirical Analysis of the Impact of Software Vulnerability Announcements on Firm Stock Price,"Security defects in software cost millions of dollars to firms in terms of downtime, disruptions, and confidentiality breaches. However, the economic implications of these defects for software vendors are not well understood. Lack of legal liability and the presence of switching costs and network externalities may protect software vendors from incurring significant costs in the event of a vulnerability announcement, unlike such industries as auto and pharmaceuticals, which have been known to suffer significant loss in market value in the event of a defect announcement. Although research in software economics has studied firms' incentives to improve overall quality, there have not been any studies which show that software vendors have an incentive to invest in building more secure software. The objectives of this paper are twofold. 1) We examine how a software vendor's market value changes when a vulnerability is announced. 2) We examine how firm and vulnerability characteristics mediate the change in the market value of a vendor. We collect data from leading national newspapers and industry sources, such as the Computer Emergency Response Team (CERT), by searching for reports on published software vulnerabilities. We show that vulnerability announcements lead to a negative and significant change in a software vendor's market value. In our sample, on average, a vendor loses around 0.6 percent value in stock price when a vulnerability is reported. We find that a software vendor loses more market share if the market is competitive or if the vendor is small. To provide further insight, we use the information content of the disclosure announcement to classify vulnerabilities into various types. We find that the change in stock price is more negative if the vendor fails to provide a patch at the time of disclosure. Also, more severe flaws have a significantly greater impact. Our analysis provides many interesting implications for software vendors as well as policy make- rs.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4267025,"By Rahul Telang , Sunil Wattal","Found in: IEEE Transactions on Software Engineering 
Issue Date:August 2007 , pp. 544-557",0
Applications of agent technology in communications: a review.,"Distance education that transmits information on the global Internet has become the trend of educational development in the coming years; however, it still has some drawbacks and shortcomings. This article focuses on how to apply Multi-Agent technology in distance learning systems. The systems are supposed to teach students individualized according to their personality characteristics and cognitive abilities by establishing Student Agent and Teacher Agent, thus, to improve the intelligence and personalization of distance education system, in order to fully tap the potential of learners and improve teaching effectiveness and learning efficiency.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5479221,S. S. Manvi and P. Venkataram.,"Computer Communications 27 (15):1493-1508, 2004.",0
Computer vision in the interface,"In this paper, we present a promising approach to systematically testing graphical user interfaces (GUI) in a platform independent manner. Our framework uses standard computer vision techniques through a python-based scripting language (Sikuli script) to identify key graphical elements in the screen and automatically interact with these elements by simulating keypresses and pointer clicks. The sequence of inputs and outputs resulting from the interaction is analyzed using grammatical inference techniques that can infer the likely internal states and transitions of the GUI based on the observations. Our framework handles a wide variety of user interfaces ranging from traditional pull down menus to interfaces built for mobile platforms such as Android and iOS. Furthermore, the automaton inferred by our approach can be used to check for potentially harmful patterns in the interface's internal state machine such as design inconsistencies (eg,. a keypress does not have the intended effect) and mode confusion that can make the interface hard to use. We describe an implementation of the framework and demonstrate its working on a variety of interfaces including the user-interface of a safety critical insulin infusion pump that is commonly used by type-1 diabetic patients.",2013,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6606669,Matthew Turk,"Communications of the ACM,   Volume 47 Issue 1, January 2004, Publisher: ACM",0
Determining the impact of software engineering research on practice.,"The impact project provides a solid and scholarly assessment of the impact software engineering research has had on software engineering practice. The assessment takes the form of a series of studies and briefings, each involving literature searches and, where possible, personal interviews.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4476222,"L. J. Osterweil, C. Ghezzi, J. Kramer, A. L. Wolf, B. Ryder, M. L. Soffa, J. Estublier, D. Rombach, M. Ciolkowski, W. Emmerich, M. Aoyama, L. A. Clarke, and D. S. Rosenblum.","Computer 41 (3):39-+, 2008.",0
Development of integrated quality information system for continuous improvement,"Based on the extensive literature review and the philosophy of integration of quality tools, the paper develops integrated quality information system (IQIS) software, and applies it to a manufacturing company. The software integrates the quality tools as well as the process quality information. It provides guidance for locating bottleneck process through integrated data analysis and also supports six sigma process improvement. The result shows that the application of IQIS can optimize the process of design and manufacturing, shorten the cycle time of product, reduce the cost, and realize quality improvement continuously",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4037135,"He, Z., Cui, Q., He, S.","(2006) ICMIT 2006 Proceedings - 2006 IEEE International Conference on Management of Innovation and Technology, 2, art. no. 4037135, pp. 830-833. Cited 1 time.",0
Digital Human Modeling for Product Lifecycle Management,The paper presents a new methodology for displaying the user's functional demands and evaluating product design for older people. Digital design models are integrated with virtual users (digital human models) generated in Jack software and refined from 3D body scanning data. The real interaction between physical design prototypes and potential users are captured by a 3D motion capture system. The captured motion is imposed onto the virtual human in Jack to perform design task analysis graphically.,2009,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5359990,H. Onan Demirel and Vincent G. Duffy,"Book Series Lecture Notes in Computer Science, Volume 4561/2007, Book Digital Human Modeling, Pages 372-380, SpringerLink Date Friday, August 24, 2007",0
Eliciting Requirements by Analysing Threats Caused by Users,"Eliciting requirements is an important issue of system development projects. Some approaches propose to identify requirements by analysing system malfunctioning. Different sources of malfunctioning are dealt with by these approaches: obstacles, conflicts, risks, etc. Our proposal is to analyse each of these sources of malfunctioning using a single notion that we call ""threat"". We propose to use this notion in a method that guides the identification and analysing of each of these sources of malfunctioning. The method helps eliciting requirements to prevent the threat. A threat is defined by a number of variables. This paper presents a literature review of all threats that relate to users. The review is based on a framework that includes several perspectives to analyse user error. The user threats is part of a global threats classification that also covers hardware, environment, design and project types of threats.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1563150,"By Elena Ivankina , Camille Salinesi","Third ACIS Int'l Conference on Software Engineering Research, Management and Applications (SERA'05) 
Issue Date:August 2005 , pp. 104-111",0
Empirical study of the effects of open source adoption on software development economics,"In this paper, we present the results of empirical study of the effects of open source software (OSS) components reuse on software development economics. Specifically, we examined three economic factors - cost, productivity, and quality. This study started with an extensive literature review followed by an exploratory study conducted through interviews with 18 senior project/quality managers, and senior software developers. Then, the result of the literature review and the exploratory study was used to formulate research model, hypotheses, and survey questionnaire. Software intensive companies from Canada and the US were targeted for this study. The period of study was between September 2004 and March 2006. Our findings show that there are strong significant statistical correlations between the factors of OSS components reuse and software development economics. The conclusion from this study shows that software organizations can achieve some economic gains in terms of software development productivity and product quality if they implement OSS components reuse adoption in a systematic way. A big lesson learned in this study is that OSS components are of highest quality and that open source community is not setting a bad example (contrary to some opinion) so far as 'good practices' are concerned.",2007,http://dl.acm.org/citation.cfm?id=1282977&CFID=932222050&CFTOKEN=89587894,"Samuel A. Ajila, Di Wu","Journal of Systems and Software,   Volume 80 Issue 9 , September 2007 , Publisher: Elsevier Science Inc.",0
Evolving Conditional Value Sets of Cost Factors for Estimating Software Development Effort,"The software cost estimation process is one of the most critical managerial activities related to project planning, resource allocation and control. As software development is a highly dynamic procedure, the difficulty of providing accurate cost estimations tends to increase with development complexity. The inherent problems of the estimation process stem from its dependence on several complex variables, whose values are often imprecise, unknown, or incomplete, and their interrelationships are not easy to comprehend. Current software cost estimation models do not inspire enough confidence and accuracy with their predictions. This is mainly due to the models' sensitivity to project data values, and this problem is amplified because of the vast variances found in historical project attribute data. This paper aspires to provide a framework for evolving value ranges for cost attributes and attaining mean effort values using the Al-oriented problem-solving approach of genetic algorithms, with a twofold aim. Firstly, to provide effort estimations by analogy to the projects classified in the evolved ranges and secondly, to identify any present correlations between effort and cost attributes.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4410279,"By Andreas S. Andreou , Efi Papatheocharous , Christos Skouroumounis","Found in: 19th IEEE International Conference on Tools with Artificial Intelligence - Vol.1 (ICTAI 2007)
Issue Date:October 2007 , pp. 165-172",0
Exploiting ?Interface Capabilities? in Overseas Markets: Lessons from Japanese Mobile Phone Handset Manufacturers in the US,,2006,http://dx.doi.org/10.1007/3-540-31248-X_7,Masanori Yasumoto and Takahiro Fujimoto,"Book Management of Technology and Innovation in Japan, Part II: Pages 143-165, SpringerLink Date Thursday, February 23, 2006",0
Formalizing Informal Stakeholder Decisions--A Hybrid Method Approach,"Decisions are hard to make when available information is incomplete, inconsistent, and ambiguous. Moreover, good-sufficiently complete, consistent, traceable, and testable-requirements are a prerequisite for successful projects. Without understanding what the stakeholders really want and need and writing these requirements in a concise, understandable and testable manner, projects will not develop what the stakeholders wanted leading to either major late rework or project termination. During the development of the WinWin negotiation model and the EasyWinWin requirements negotiation method, we have gained considerable experience in capturing decisions made by stakeholders in over 100 projects. However, the transition from informal decisions to requirements specification is still a challenging problem. Based on our analysis of the projects to date, we have developed an integrated set of gap-bridging methods as a hybrid method to support stakeholders making better decisions in order to eliminate requirements related problems and ease the process of formality transition",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4076956,"By Hasan Kitapci , Barry W. Boehm","Found in: 40th Annual Hawaii International Conference on System Sciences (HICSS'07) 
Issue Date:January 2007 , pp. 283c",0
General principles of construction of knowledge computer systems,"Steep development of computer systems has created a great variety of important technical and scientific problems: for development of an architecture of algorithms, control circuits for access to common resources, and computing structures and distributed database structures. In this paper, the principles of parallelism for the construction of multilevel distributed computer networks are given.",2003,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1255048,Yu. V. Kapitonova,"Cybernetics and Systems Analysis, Volume 42, Number 4 / July, 2006",0
Higher Order Pheromone Models in Ant Colony Optimisation,"As a meta-heuristic approach, Ant colony optimization (ACO) has many applications. In the algorithm selection of pheromone models is the top priority. Selecting pheromone models that don't suffer negative biases is a natural choice. Specifically for the travelling salesman problem, the first order pheromone is widely recognized.When come across travelling salesman problem, we study the reasons for the success of ant colony optimization from the perspective of pheromone models,and unify different order pheromone models. In tests, we have introduced the concept of sample locations and the similarity coefficient to pheromone models. The first order pheromone model and the second order pheromone model are compared and are further analysed. We illustrate that the second order pheromone model has better global search ability and diversity of population than the former. With appropriate-scale travelling salesman problems, the second order model performs better than the first order pheromone model.",2017,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7887484,James Montgomery,"Book Series Lecture Notes in Computer Science, Publisher Springer Berlin / Heidelberg, ISSN 0302-9743 (Print) 1611-3349 (Online), Volume 4150/2006, Book Ant Colony Optimization and Swarm Intelligence, Pages 17-29, SpringerLink Date Tuesday, March 09, 2004",0
How influential is Brooks' Law? A longitudinal citation context analysis of Frederick Brooks' The Mythical Man-Month,"<p>Citation context analysis is used to demonstrate the diversity of concept symbols that a book-length publication can represent and the diffusion of influence of these concepts over time and across scholarly disciplines. A content analysis of 574 citation contexts from 497 journal articles citing an edition of Frederick P. Brooks, Jr's <bi>The Mythical Man-Month (MMM)</bi> over the period 1975-1999 showed that <bi>MMM</bi> represents a variety of different concepts and is cited in a wide range of subject areas. Over time, a high level of interest in <bi>MMM</bi> spread from software engineering and computer science to management and information systems, with different areas showing different patterns of focus on concepts within the work. 'Brooks' Law' (the 'mythical man-month' or 'adding more people to a late project makes it later'), accounted for less than 30% of the classified citation contexts. The findings contribute to our understanding of the diffusion of ideas in scholarly communication, and the diversity that can underlie the creation of a reference in a scholarly publication.</p>",2006,http://dl.acm.org/citation.cfm?id=1137567&CFID=932211745&CFTOKEN=68617231,"Katherine W. McCain, Laura J. Salvucci","June 2006, Journal of Information Science,   Volume 32 Issue 3, Publisher: Sage Publications, Inc.",0
Immune System Approaches to Intrusion Detection ? A Review,"The Battery-Sensing Intrusion Protection System (B-SIPS) [1] initially took a non-conventional approach to intrusion detection by recognizing attacks based on anomalous Instantaneous Current (IC) drain. An extension of B-SIPS, the Multi-Vector Portable Intrusion Detection System (MVP-IDS) validates the idea of recognizing attacks based on anomalous IC drain by correlating the detected anomalies with wireless attack traffic from both the Wi-Fi and Bluetooth mediums. To effectively monitor the Wi-Fi and Bluetooth mediums for malicious packet streams, the Snort-Based Wi-Fi and Bluetooth Attack Detection and Signature System (BADSS) modules were introduced. This paper illustrates how a blended strategy of using a low overhead tripwire can be combined with more sophisticated detection mechanisms to provide an effective protection system for limited resource wireless information technology devices.",2010,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=5612449,"Uwe Aickelin, Julie Greensmith and Jamie Twycross","Book Series Lecture Notes in Computer Science, Volume 3239/2004, Book Artificial Immune Systems, Pages 316-329, SpringerLink Date Thursday, August 19, 2004",0
In-house software development: What project management practices lead to success?,"Project management is an important part of software development, both for organizations that rely on third-party software development and for those whose software is developed primarily in-house. Moreover, quantitative survey-based research regarding software development's early, nontechnical aspects is lacking. To help provide a project management perspective for managers responsible for in-house software development, we conducted a survey in an attempt to determine the factors that lead to successful projects. We chose a survey because of its simplicity and because we hoped to find relationships among variables. Also, a survey let us cover more projects at a lower cost than would an equivalent number of interviews or a series of case studies. Our results provide general guidance for business and project managers to help ensure that their projects succeed.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1377129,J. M. Verner and W. M. Evanco.,"Ieee Software 22 (1):86-+, 2005.",0
Mathematical Methods for Shape Analysis and form Comparison in 3D Anthropometry: A Literature Review,"<p>Form comparison is a fundamental part of many anthropometric, biological, anthropological, archaeological and botanical researches, etc. In traditional anthropometric form comparison methods, geometry characteristics and internal structure of surface points are not adequately considered. Form comparison of 3D anthropometric data can make up the deficiency of traditional methods. In this paper, methods for analyzing 3D other than 2D objects are highlighted. We summarize the advance of form comparison techniques in the last decades. According to whether they are based upon anatomical landmarks, we partition them into two main categories, landmark-based methods and landmark-free methods. The former methods are further sub-divided into deformation methods, superimposition methods, and methods based on linear distances, while the latter methods are sub-divided into shape statistics-based methods, methods based on function analysis, view-based methods, topology-based methods, and hybrid methods. Examples for each method are presented. The discussion about their advantages and disadvantages are also introduced.</p>",2007,http://dl.acm.org/citation.cfm?id=1784095&CFID=932213268&CFTOKEN=78614827,"Jianwei Niu, Zhizhong Li and Gavriel Salvendy","Book Series Lecture Notes in Computer Science, Volume 4561/2007, Book Digital Human Modeling, Pages 161-170
Subject Collection Computer Science, SpringerLink Date Friday, August 24, 2007",0
Microformats: The Next (Small) Thing on the Semantic Web?,"Clever application of existing XHTML elements and class attributes can make it easier to describe people, places, events, and other semistructured information in human-readable form. In this paper, the author takes a more detailed look at some examples of microformats, the general principles by which they can be constructed, and how a community of users is forming around these seemingly ad hoc specifications to advance the cause of what some call an alternative to the semantic Web, the ""lowercase semantic Web"".",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1580416,By Rohit Khare,"Found in: IEEE Internet Computing 
Issue Date:January 2006 
pp. 68-75",0
Mobrex: Visualizing Users' Mobile Browsing Behaviors,"This paper deals with the Mobile Browsing Explorer (Mobrex) to give analysts a set of interactive visualizations that highlight various aspects of how users browse an information space. Here, we describe the tool and demonstrate its support of a user study of three browsing techniques for mobile maps. Although we mainly focus here on PDAs and mobile map browsing, Mobrex can easily support analysts studying user interaction with other information spaces and other devices, including mobile phones and desktop computers.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4418746,"By Stefano Burigat , Luca Chittaro , Lucio Ieronutti","Found in: IEEE Computer Graphics and Applications 
Issue Date:January 2008 
pp. 24-32",0
Never the CS and IS Twain Shall Meet?,"An enormous intellectual distance exists between the fields of computer science and information systems, which needs to be fixed soon.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1504677,By Robert L. Glass,"Found in: IEEE Software  
Issue Date:September 2005 
pp. 120, 119",0
On the adaptation of Grounded Theory procedures: Insights from the evolution of the 2G method,"Purpose
? To articulate the interpretations and adaptations of Grounded Theory made within the 2G method, and the motivations behind them.

Design/methodology/approach
? Literature review and conceptual approach reflecting on the authors' experience of having developed the 2G method.

Findings
? Identifies six adaptations of Grounded Theory as being of particular interest. Five relate to method procedures, namely: developing a core category; coding interview data; exposing evolving theories to stakeholders; developing multiple concept frameworks; and inter?linking concepts. The sixth relates to expectations on method users, and the tension between expertise relating to the phenomenon being analysed, and openness in interpreting the data.

Research limitations/implications
? Shows how Grounded Theory procedures have been adapted and used in IS methods. Specifically, the paper illustrates and makes explicit how a specific method (the 2G method) has evolved.

Practical implications
? Provides insights for users of Grounded Theory (GT) and developers of IS methods on how GT procedures have been interpreted and adapted in previous and the authors' own research.

Originality/value
? Provides insights into how Grounded Theory (GT) procedures have been adapted for use in other IS methods, with insights from the authors' own experience of having developed the 2G method. Reflects on the use of GT procedures in a number of case studies related to tool evaluation. Identifies six areas in which specific interpretations or adaptations of GT were considered necessary in the contexts in which the studies were undertaken, and justifies these six departures from standard interpretations of GT procedures.",2005,http://www.emeraldinsight.com/doi/abs/10.1108/09593840510615842,"Lings, B.a , Lundell, B.b","(2005) Information Technology and People, 18 (3), pp. 196-211.",0
Open Source Software in Industry,"Many of today's most innovative products and solutions are developed on the basis of free and open source software (FOSS). Most of us can no longer imagine the world of software engineering without open source operating systems, databases, application servers, Web servers, frameworks, and tools. Brands such as Linux, MySQL, Apache, and Eclipse have shaped product and service development. They facilitate competition and open markets as well as innovation to meet new challenges. De facto FOSS standards such as Eclipse and Corba simplify the integration of products, whether they're all from one company or from multiple suppliers. IEEE Software has assembled this theme section to provide a brief yet practical overview of where FOSS is heading.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4497764,By Christof Ebert,"Found in: IEEE Software 
Issue Date:May 2008 
pp. 52-53",0
Practical Guidelines for Expert-Judgment-Based Software Effort Estimation,"This article presents seven guidelines for producing realistic software development effort estimates. The guidelines derive from industrial experience and empirical studies. While many other guidelines exist for software effort estimation, these guidelines differ from them in three ways: 1) They base estimates on expert judgments rather than models. 2) They are easy to implement. 3) They use the most recent findings regarding judgment-based effort estimation. Estimating effort on the basis of expert judgment is the most common approach today, and the decision to use such processes instead of formal estimation models shouldn't be surprising. Simple process changes such as reframing questions can lead to more realistic estimates of software development efforts.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1438330,By Magne Jorgensen,"Found in: IEEE Software 
Issue Date:May 2005 , pp. 57-63",0
Predicting Bugs from History,"The author gives an indication of the accuracy attainable with RF numerical methods in the prediction of those quantities which depend upon the near-field of radiating structures. A wire-mesh RF mathematical model of a medium size airliner is described. Using this model, and with NEC as the solution code, predictions are presented of the terminal reactance of an installed `long-wire' HF antenna. These represent true predictions rather than `post-dictions' because the RF mathematical model does not incorporate any empirically derived information. The difficulties involved in obtaining the corroborative measurements are examined and direct comparison with the predictions is made. The particular antenna configuration chosen for this study is considered to constitute a stringent test of the predictions. The agreement between calculation and subsequent measurement is fair",1991,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=98339,"Thomas Zimmermann, Nachiappan Nagappan and Andreas Zeller","Book Software Evolution, Part I, Pages 69-88, SpringerLink Date Friday, January 25, 2008",0
Project Management within Virtual Software Teams,"When implementing software development in a global environment, a popular strategy is the establishment of virtual teams. The objective of this paper is to examine the effective project management of this type of team. In the virtual team environment problems arise due to the collaborative nature of software development and the impact distance introduces. Distance specifically impacts coordination, visibility, communication and cooperation within a virtual team. In these circumstances the project management of a virtual team must be carried out in a different manner to that of a team in a single-site location. Results from this research highlighted six specific project management related areas that need to be addressed to facilitate successful virtual team operation. Organizational structure, risk management, infrastructure, process, conflict management and team structure and organization. Additional related areas are the sustained support of senior management and the provision of effective infrastructure",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4031740,"By Valentine Casey , Ita Richardson","Found in: International Conference on Global Software Engineering (ICGSE'06)
Issue Date:October 2006 
pp. 33-42",0
Protocols in the use of empirical software engineering artifacts,"Ethnography is a powerful qualitative empirical approach which can be used to understand and hence improve work practice. Ethnographically-informed methods are widely adopted in the Social Sciences but are not so popular with software engineering researchers. As with many inter-disciplinary approaches, ethnographic methods can be misunderstood and misapplied, leading to results being dismissed with a &#x201C;so what?&#x201D; response. Drawing on my own and other's experience of applying this approach in empirical studies of software practice, I will provide an overview of the role of ethnography in Software Engineering research. I will describe the use of ethnographic methods as a means to provide an in-depth understanding of the socio-technological realities surrounding everyday software development practice. The knowledge gained can be used to understand developers' work practices, to inform the development of new processes, methods and tools, and to evaluate and evolve existing practices.",2012,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6272512,"Victor R. Basili, Marvin V. Zelkowitz, Dag I. K. Sj?berg, Philip Johnson and Anthony J. Cowling","Empirical Software Engineering, Volume 12, Number 1 / February, 2007",0
"Software engineering: The past, the future, and your TCSE.","Although it has seen some spectacular successes, the software engineering field still has room for improvement. The Technical Council on Software Engineering is committed to advancing the development, application, and adoption of software engineering.",2005,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1463217,K. Read.,"Ieee Software 22 (4):106-107, 2005.",0
Statistical significance testing - a panacea for software technology experiments?,"<p>Empirical software engineering has a long history of utilizing statistical significance testing, and in many ways, it has become the backbone of the topic. What is less obvious is how much consideration has been given to its adoption. Statistical significance testing was initially designed for testing hypotheses in a very different area, and hence the question must be asked: does it transfer into empirical software engineering research? This paper attempts to address this question. The paper finds that this transference is far from straightforward, resulting in several problems in its deployment within the area. Principally problems exist in: formulating hypotheses, the calculation of the probability values and its associated cut-off value, and the construction of the sample and its distribation. Hence, the paper concludes that the topic should explore other avenues of analysis, in an attempt to establish which analysis approaches are preferable under which conditions, when conducting empirical software engineering studies.</p>",2004,http://dl.acm.org/citation.cfm?id=1035096&CFID=932212851&CFTOKEN=68964170,J. Miller.,"Journal of Systems and Software 73 (2):183-192, 2004.",0
The art and science of software architecture.,"In this paper we propose some security mechanisms that can be used in a multimedia content distribution system with digital rights management (DRM) to ensure that the software tools used in the client side are trusted not only in the moment when they are installed but during their whole life operation. For this purpose, certification, verification, reverification and recertification mechanisms are described, discussing the advantages as well as the drawbacks of using such techniques. A complex use case is presented to complement the description of the proposed mechanisms. The presented architecture and mechanisms are being implemented in the AXMEDIS project, which aims to create an innovative technology framework for the automatic production, protection and distribution of digital cross media contents over a range of different media channels, including PC (on the Internet), PDA, kiosks, mobile phones and i-TV.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4402860,A. W. Brown and J. A. McDermid.,"International Journal of Cooperative Information Systems 16 (3-4):439-466, 2007.",0
Using Repository of Repositories (RoRs) to Study the Growth of F/OSS Projects: A Meta-Analysis Research Approach,"AbstractFree/Open Source Software (F/OSS) repositories contain valuable data and their usefulness in studying software development and community activities continues to attract a lot of research attention. A trend in F/OSS studies is the use of metadata stored in a repository of repositories or RoRs. This paper utilizes data obtained from such RoRs -FLOSSmole- to study the types of projects being developed by the F/OSS community. We downloaded projects by topics data in five areas (Database, Internet, Software Development, Communications, and Games/Entertainment) from Flossmoles raw and summary data of the sourceforge repository. Time series analysis show the numbers of projects in the five topics are growing linearly. Further analysis supports our hypothesis that F/OSS development is moving up the stack from developer tools and infrastructure support to end-user applications such as Databases. The findings have implications for the interpretation of the F/OSS landscape, the utilization and adoption of open source databases, and problems researchers might face in obtaining and using data from RoRs.",2007,http://dx.doi.org/10.1007/978-0-387-72486-7_12,"Sulayman K. Sowe, L. Angelis, I. Stamelos and Y. Manolopoulos","Book Series IFIP International Federation for Information Processing, Volume 234/2007, Book Open Source Development, Adoption and Innovation, Pages 147-160, SpringerLink Date Friday, August 10, 2007",0
Using RFID Technologies to Capture Simulation Data in a Hospital Emergency Department,"Simulation professionals understand the importance of accurate data for model validation. Traditional sources of simulation data come from information technology systems, manual records from staff, observations, and estimates by subject matter experts. This paper discusses how radio frequency identification (RFID) technologies were used on a recent consulting engagement at a hospital. Data collected through RFID can validate or replace activity duration estimates from traditional sources. However, the accuracy and cost effectiveness of RFID is not guaranteed. A sound methodology was developed, which included rigorous planning and testing of hardware, processes and data analysis. Hardware vendors needed to understand what the simulation required so they could properly setup equipment and software. Also, ED staff needed to understand the purpose of this data collection to avoid anxiety about personnel evaluations. Finally, efficient and reliable issue and collection of patient tags was crucial to the success of this effort",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4117760,"By M.J. Miller , D.M. Ferrin , T. Flynn , M. Ashby , K. Preston White , M.G. Mauer","Found in: Proceedings of the 2006 Winter Simulation Conference  
Issue Date:December 2006 
pp. 1365-1371",0
Web engineering security: a practitioner's perspective,"Security is an elusive target in today's high-speed and extremely complex, Web enabled, information rich business environment. This paper presents the idea that there are essential, basic organizational elements that need to be identified, defined and addressed before examining security aspects of a Web engineering development process. These elements are derived from empirical evidence based on a Web survey and supporting literature. This paper makes two contributions. The first contribution is the identification of the Web engineering specific elements that need to be acknowledged and resolved prior to the assessment of a Web engineering process from a security perspective. The second contribution is that these elements can be used to help guide security improvement initiatives in Web engineering",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4159866,"William Bradley Glisson, Andrew McDonald, Ray Welland","ICWE '06: Proceedings of the 6th international conference on Web engineering , July 2006 , Publisher: ACM",0
2D-3D MultiAgent GeoSimulation with Knowledge-Based Agents of Customers? Shopping Behavior in a Shopping Mall,"<p>In this paper we present a simulation prototype of the customers&#39; shopping behavior in a mall using a knowledge-based multiagent geosimulation approach. The shopping behavior in a shopping mall is performed in a geographic environment (a shopping mall) and is influenced by several shopper&#39;s characteristics (internal factors) and factors which are related to the shopping mall (external or situational factors). After identifying these <i>factors</i> from a large literature review we grouped them in what we called &#8220;<i>dimensions</i>&#8221;. Then we used these dimensions to design the knowledge-based agents&#39; models for the shopping behavior simulation. These models are created from empirical data and implemented in the MAGS geosimulation platform. The empirical data have been collected from questionnaires in the <i>Square One shopping mall</i> in Toronto (Canada). After presenting the main characteristics of our prototype, we discuss how mall&#39;s managers of the <i>Square One </i>can use the Mall_MAGS prototype to make decisions about the mall spatial configuration by comparing different simulation scenarios. The simulation results are presented to mall&#39;s managers through a user-friendly tool that we developped to carry out data analysis.</p>",2005,http://dl.acm.org/citation.cfm?id=2156644&CFID=932214625&CFTOKEN=82614389,Walid Ali and Bernard Moulin,"Book Series Lecture Notes in Computer Science, Volume 3693/2005, Book Spatial Information Theory, Pages 445-458, SpringerLink Date Tuesday, September 27, 2005",0
2nd International Workshop on Realising Evidence-Based Software Engineering (REBSE-2),"The REBSE international workshops are concerned with exploring the adaptation and use of the evidence-based paradigm in software engineering research and practice. The workshops address this goal through a mix of presentations and discussion, drawing upon ideas and experiences from other disciplines where appropriate.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4222713,"David Budgen, Barbara Kitchenham, Pearl Brereton, Mark Turner","ICSE COMPANION '07: Companion to the proceedings of the 29th International Conference on Software Engineering , May 2007 , Publisher: IEEE Computer Society",0
2nd InternationalWorkshop on Realising Evidence-Based Software Engineering (REBSE-2): Overview and Introduction,"The REBSE international workshops are concerned with exploring the adaptation and use of the evidence-based paradigm in software engineering research and practice, through a mix of presentations and discussion. Here, we provide some background about evidence-based software engineering and its current state.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4273273,"Barbara Kitchenham, David Budgen, Pearl Brereton, Mark Turner","REBSE '07: Proceedings of the Second International Workshop on Realising Evidence-Based Software Engineering  , May 2007",0
A Bayesian Approach to Modelling Users? Information Display Preferences,"<p>This paper describes the process by which we constructed a user model for ERST &#8211; an External Representation Selection Tutor &#8211; which recommends external representations (ERs) for particular database query task types based upon individual preferences, in order to enhance ER reasoning performance. The user model is based on experimental studies which examined the effect of background knowledge of ERs upon performance and preferences over different types of tasks.</p>",2005,http://dl.acm.org/citation.cfm?id=2136778&CFID=932218970&CFTOKEN=17001112,Beate Grawemeyer and Richard Cox,"Book Series: Lecture Notes in Computer Science, Publisher Springer Berlin / Heidelberg, ISSN 0302-9743 (Print) 1611-3349 (Online), Volume 3538/2005, Book: User Modeling 2005, ISBN 978-3-540-27885-6,  Pages 225-230, SpringerLink Date Friday, August 19, 2005",0
A Bayesian Model for Predicting Reliability of Software Systems at the Architectural Level,"<p>Modern society relies heavily on complex software systems for everyday activities. Dependability of these systems thus has become a critical feature that determines which products are going to be successfully and widely adopted. In this paper, we present an approach to modeling reliability of software systems at the architectural level. Dynamic Bayesian Networks are used to build a stochastic reliability model that relies on standard models of software architecture, and does not require implementation-level artifacts. Reliability values obtained via this approach can aid the architect in evaluating design alternatives. The approach is evaluated using sensitivity and uncertainty analysis.</p>",2007,http://dl.acm.org/citation.cfm?id=1784871&CFID=932215938&CFTOKEN=72635320,"Roshanak Roshandel, Nenad Medvidovic and Leana Golubchik","Book Series Lecture Notes in Computer Science, Volume 4880/2008, Book Software Architectures, Components, and Applications, Pages 108-126, SpringerLink Date Wednesday, January 30, 2008",0
A brief survey of program slicing,"This paper presents a survey about different types of fuzzy information measures. A number of schemes have been proposed to combine the fuzzy set theory and its application to the entropy concept as a fuzzy information measurements. The entropy concept, as a relative degree of randomness, has been utilized to measure the fuzziness in a fuzzy set or system. However, a major difference exists between the classical Shannon entropy and the fuzzy entropy. In fact while the later deals with vagueness and ambiguous uncertainties, the former tackles probabilistic uncertainties (randomness)",2001,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1008855,"Baowen Xu, Ju Qian, Xiaofang Zhang, Zhongqiang Wu, Lin Chen","ACM SIGSOFT Software Engineering Notes,   Volume 30 Issue 2, March 2005, Publisher: ACM",0
A Case History of International Space Station Requirement Faul,"There is never enough time or money to perform verification and validation (V&amp;V) or independent verification and validation (IV&amp;V) on all aspects of a software development project, particularity for complex computer systems. We have only high-level knowledge of how the potential existence of specific requirements faults increases project risks, and of how specific V&amp;V techniques (requirements tracing, code analysis, etc.) contribute to improved software reliability and reduced risk. An approach to this problem, fault-based analysis, is proposed and a case history of the National Aeronautics and Space Administration's (NASA) International Space Station (ISS) project is presented to illustrate its use. Specifically, a tailored requirement fault taxonomy was used to perform trend analysis of the historical profiles of three ISS computer software configuration items as well as to build a prototype common cause tree. ISS engineers evaluated the results and extracted lessons learned",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1690351,"By Jane Huffman Hayes , Inies C.M. Raphael , Elizabeth Ashlee Holbrook , David M. Pruett","Found in: 11th IEEE International Conference on Engineering of Complex Computer Systems (ICECCS'06) 
Issue Date:August 2006 
pp. 17-26",0
A case study of combining i* framework and the Z notation,"Agent-oriented conceptual modeling (AoCM) frameworks are gaining wider popularity in software engineering. In this paper, we are using AoCM framework i* and the Z notation together for requirements engineering (RE). Most formal techniques like Z are suitable for and designed to work in the later phases of RE and early design stages of system development. We argue that early requirements analysis is a very crucial phase of software development. Understanding the organisational environment, reasoning and rationale underlying requirements along with the goals and social dependencies of its stakeholders are important to model and build effective computing systems. The i* framework is one such language which addresses early stage RE issues cited above extremely well. It supports the modeling of social dependencies between agents with respect to tasks and goals both functional and non-functional. We have developed a methodology involving the combined use of i* and the Z notation for agent-oriented RE. In our approach we suggest to perform one-to-one mapping between i* framework and Z. At the first instance general i* model has been mapped into Z schemas, and then i* diagrams of the Emergency Flood Rescue Management Case Study are mapped into Z. Some steps explaining further information refinement with examples are also provided. Using Z specification schemas, we are in a position to express properties that are not restricted to the current state of the system, but also to its past and future history. The case study described in this paper is taken from one of the most important responsibilities of the emergency services agency, managing flood rescue and evacuation operations. By using this case study, we have tested the effectiveness of our methodology to a real-life application",2004,http://core.ecu.edu/vilkomirs/papers/vilkomir-iceis.pdf,"Aneesh Krishna, Sergiy Vilkomir, Aditya Ghose","Proceedings of ICEIS-2004: The 6th International Conference on Enterprise Information Systems, Porto",0
A Case Study of Reading Techniques in a Software Company,"Software inspection is an efficient method to detect faults early in the software lifecycle. This has been shown in several empirical studies together with experiments on reading techniques. However, experiments in industrial settings are often considered expensive for a software organization. Hence, many evaluations are performed in the academic environment with artificial documents. In this paper, we describe an empirical study in a software organization where a requirements document under development is used to compare two reading techniques. There are several benefits as well as drawbacks of using this kind of approach, which are extensively discussed in the paper. The reading techniques compared is the standard technique used in the organization (checklist-based) with the test perspective of perspective-based reading. The main result is that the test perspective of perspective-based reading seems more effective and efficient than the company standard method. The impact of this study is that the software organization will apply the new reading technique in future requirements inspections.",2004,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1334910,"By Tomas Berling , Thomas Thelin","Found in: 2004 International Symposium on Empirical Software Engineering (ISESE'04) ,Issue Date:August 2004 , pp. 229-238",0
A Case Study: CRM Adoption Success Factor Analysis and Six Sigma DMAIC Application,"With today's increasingly competitive economy, many organizations have initiated customer relationship management (CRM) projects to improve customer satisfaction, revenue growth and employee productivity gains. However, only a few successful CRM implementations have successfully completed. In order to enhance the CRM implementation process and increase the success rate, in this paper, first we present the most significant success factors for CRM implementation identified by the results of literature reviews and a survey we conducted. Then we propose a strategy to integrate Six Sigma DMAIC methodology with the CRM implementation process addressing five critical success factors (CSF). Finally, we provide a case study to show how the proposed approach can be applied in the real CRM implementation projects. We conclude that by considering the critical success factors, the proposed approach can emphasize the critical part of implementation process and provide high possibility of CRM adoption success.",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4297022,"By Zhedan Pan , Hoyeon Ryu , Jongmoon Baik","Found in: 5th ACIS International Conference on Software Engineering Research, Management & Applications (SERA 2007) 
Issue Date:August 2007 , pp. 828-838",0
A cautionary note on checking software engineering papers for plagiarism.,"Several tools are marketed to the educational community for plagiarism detection and prevention. This article briefly contrasts the performance of two leading tools, TurnItIn and MyDropBox, in detecting submissions that were obviously plagiarized from articles published in IEEE journals. Both tools performed poorly because they do not compare submitted writings to publications in the IEEE database. Moreover, these tools do not cover the Association for Computing Machinery (ACM) database or several others important for scholarly work in software engineering. Reports from these tools suggesting that a submission has ldquopassedrdquo can encourage false confidence in the integrity of a submitted writing. Additionally, students can submit drafts to determine the extent to which these tools detect plagiarism in their work. Because the tool samples the engineering professional literature narrowly, the student who chooses to plagiarize can use this tool to determine what plagiarism will be invisible to the faculty member. An appearance of successful plagiarism prevention may in fact reflect better training of students to avoid plagiarism detection.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4455465,C. Kaner and R. L. Fiedler.,"Ieee Transactions on Education 51 (2):184-188, 2008.",0
"A citation analysis of the ACE2005--2007 proceedings, with reference to the June 2007 CORE conference and journal rankings","<p>This paper compares the CORE rankings of computing education conferences and journals to the frequency of citation of those journals and conferences in the ACE2005, 2006 and 2007 proceedings. The assumption underlying this study is that citation rates are a measure of esteem, and so there should be a positive relationship between citation rates and rankings. The CORE conference rankings appear to broadly reflect the ACE citations, but there are some inconsistencies between citation rates and the journal rankings. The paper also identifies the most commonly cited books in these ACE proceedings. Finally, in the spirit of ""<i>Quis custodiet ipsos custodes?""</i> the paper discusses some ways in which the CORE rankings process itself might in future be made more transparent and open to scholarly discourse.</p>",2008,http://dl.acm.org/citation.cfm?id=1379258&CFID=932218899&CFTOKEN=37645224,"Raymond Lister, Ilona Box","ACE '08: Proceedings of the tenth conference on Australasian computing education - Volume 78,   Volume 78 , January 2008, Publisher: Australian Computer Society, Inc.",0
A Classification Proposal for Computer-Assisted Knee Systems,"This paper compares classification techniques to identify several power quality disturbances in a frame of smart metering design for smart grids with high penetration of PV systems. These techniques are: Linear Discriminant Analysis (LDA), Nearest Neighbor Method (kNN), Learning Vector Quantization (LVQ) and Support Vector Machine (SVM). For this purpose, fourteen power-quality features based in higher-order statistics are used to assist classification. Special attention is paid to the spectral kurtosis, whose nature enables measurement options related to the impulsiveness of the power quality events. The best technique of those compared is selected according to correlation and mistake rates. Results clearly reveal the potential capability of the methodology in classifying the single disturbances. Concretely, the SVM classifier obtained an average correlation rate of 99%. Hence, concluding that it is a robust classification method.",2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7125534,"F. Picard, J. Moody, B. Jaramaz, A. DiGioia, C. Nikou and R.S. LaBarca","Book Series Lecture Notes in Computer Science, Volume 1935/2000, Book Medical Image Computing and Computer-Assisted Intervention ? MICCAI 2000, Pages 1145-1151, SpringerLink Date Wednesday, February 11, 2004",0
A Cognitive-Based Mechanism for Constructing Software Inspection Teams,"Software inspection is well-known as an effective means of defect detection. Nevertheless, recent research has suggested that the technique requires further development to optimize the inspection process. As the process is inherently group-based, one approach to improving performance is to attempt to minimize the commonality within the process and the group. This work proposes an approach to add diversity into the process by using a cognitively-based team selection mechanism. The paper argues that a team with diverse information processing strategies, as defined by the selection mechanism, maximize the number of different defects discovered.",2004,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1359772,Zhichao Yin / James Miller,"IEEE Transactions on Software Engineering,   Volume 30 Issue 11, November 2004, Publisher: IEEE Press",0
A Collaborative Augmented Reality System Using Transparent Display,"Augmented reality is a technique to integrate the virtual (i.e., computer-generated) information with objects in the real world. Real world objects can thus be augmented in their properties and functions with the help of a computer. One of the authors has proposed an augmented reality system in which a transparent display is used as a means of integration of the real world and the virtual world. This paper discusses an extension of the system so that it can be used in a collaborative working environment. Capturing the gesture as a means of user interaction is realized by a single camera, aiming at simplifying the system setup and image analysis. We propose an idea of utilizing statistical data of human body and human's perceptional characteristics, as well as vision techniques. Two applications are presented to explain the usefulness of the system: one is a game-like application, which we call mind-to-mind communication, and the other a messenger object.",2004,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1376689,"By Masahito Hirakawa , Satoshi Koike","Found in: IEEE Sixth International Symposium on Multimedia Software Engineering (ISMSE'04) 
Issue Date:December 2004 
pp. 410-416",0
A comparative analysis of the efficiency of change metrics and static code attributes for defect prediction,"In this paper we present a comparative analysis of the predictive power of two different sets of metrics for defect prediction. We choose one set of product related and one set of process related software metrics and use them for classifying Java files of the Eclipse project as defective respective defect-free. Classification models are built using three common machine learners: logistic regression, naive Bayes, and decision trees. To allow different costs for prediction errors we perform cost-sensitive classification, which proves to be very successful: &gt;75% percentage of correctly classified files, a recall of &gt;80%, and a false positive rate &lt;30%. Results indicate that for the Eclipse data, process metrics are more efficient defect predictors than code metrics.",2008,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4814129,"Raimund Moser, Witold Pedrycz, Giancarlo Succi","May 2008 
ICSE '08: Proceedings of the 30th international conference on Software engineering 
Publisher: ACM
ABSTRACT",0
A Comparative Longitudinal Study of Non-verbal Mouse Pointer,"<p>A longitudinal study of two non-speech continuous cursor control systems is presented in this paper: Whistling User Interface (U<sup>3</sup>I) and Vocal Joystick (VJ). This study combines the quantitative and qualitative methods to get a better understanding of novice users' experience over time. Three hypotheses were tested in this study. The quantitative data show that U<sup>3</sup>I performed better in error rate and in simulating a mouse click; VJ was better on other measures. The qualitative data indicate that the participants' opinions regarding both tools improved day-by-day. U<sup>3</sup>I was perceived as less fatiguing than VJ. U<sup>3</sup>I approached the performance of VJ at the end of the study period, indicating that these two systems can achieve similar performances as users get more experienced in using them. This study supports two hypotheses but does not provide enough evidence to support one hypothesis.</p>",2007,http://dl.acm.org/citation.cfm?id=1778386&CFID=932210075&CFTOKEN=11825007,"Murni Mahmud, Adam J. Sporka, Sri H. Kurniawan and Pavel Slav?k","Book Series Lecture Notes in Computer Science, Volume 4663/2007, Book Human-Computer Interaction ? INTERACT 2007, Pages 489-502, SpringerLink Date Friday, September 07, 2007",0
A Comparison of Requirements Specification Methods from a Software Architecture Perspective,"One of the key challenges to producing high-quality software architecture is identifying and understanding the software's architecturally significant requirements. These requirements are the ones that have the most far-reaching effect on the architecture. In this report, five methods for the elicitation and expression of requirements are evaluated with respect to their ability to capture architecturally significant requirements. The methods evaluated are requirements specification using natural language, use case analysis, the Quality Attribute Workshop (developed by the Carnegie Mellon Software Engineering Institute), global analysis, and an approach developed by Fergus O'Brien. These methods were chosen because they are in widespread use or emphasize the capture of architecturally significant requirements. Three problems must be solved to systematically transform business and mission goals into architecturally significant requirements: (1) the requirements must be expressed in a form that provides the information necessary for design; (2) the elicitation of the requirements must capture architecturally significant requirements; and (3) the business and mission goals must provide systematic input for elicitation process. The primary finding from the evaluation of these methods is that there are promising solutions to the first two problems. However, there is no method for systematically considering the business and mission goals in the requirements elicitation.",2006,http://repository.cmu.edu/sei/389/,"Len Bass, John Bergey, Paul Clements, Paulo Merson, Ipek Ozkaya, Raghvinder Sangwan","TECHNICAL REPORT, CMU/SEI-2006-TR-013, ESC-TR-2006-013, August 2006",0
A comprehensive synthesis of research,The paper introduces the concept of reflection matrices in the coupling matrix filter reconfiguration. It is shown that reflection matrices are complementary to rotation matrices a useful concept that can be used alternatively to rotation matrices in the similarity transformations that are applied in order to transform the coupling matrix to a suitable form. A cross-coupled filter example is given where both concepts are used.,2015,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7411795,Niki Davis and Roger Carlsen,"Book Series IFIP International Federation for Information Processing, Volume 161/2005, Book Education and the Knowledge Society, Pages 3-14, SpringerLink Date Saturday, December 17, 2005",0
A Computational Method for Viewing Molecular Interactions in Docking,"<p>A huge amount of molecular data is available in protein data bank and various other libraries and this amount is increasing day by day. Devising new and efficient computational methods to extract useful information from this data is a big challenge for the researchers working in the field. Computational molecular docking refers to computational methods which attempt to obtain the best binding conformation of two interacting molecules. Information of the best binding conformation is useful in many applications such as rational drug design, recognition, cellular pathways, macromolecular assemblies, protein folding etc. Docking has three important aspects: (i) modeling of molecular shape, (ii) shape matching and (iii) scoring and ranking of potential solutions. In this paper, a new approach is proposed for shape matching in rigid body docking. The method gives visual information about the matching conformations of the molecules. In the approach proposed here, B-spline surface representation technique is used to model the patches of molecular surface. Surface normal and curvature properties are used to match these patches with each other. The 2-D approach used here for generation of surface patches is useful to pixellisation paradigm.</p>",2006,http://dl.acm.org/citation.cfm?id=1759380&CFID=932209984&CFTOKEN=73070729,"Vipin K. Tripathi, Bhaskar Dasgupta and Kalyanmoy Deb","Book Series Lecture Notes in Computer Science, Volume 4370/2007, Book Pixelization Paradigm, Pages 152-163, SpringerLink Date Saturday, May 19, 2007",0
A Computerized Infrastructure for Supporting Experimentation in Software Engineering,"Software engineering (SE) is predominantly a team effort that needs close cooperation among several people who may be geographically distributed. It has been recognized that appropriate tool support is a prerequisite to improve cooperation within SE teams. In an effort to contribute to this line of research, we have designed and developed an infrastructure, called ABC4GSD, based on the models of activity theory (AT) and the principles of the activity-based computing (ABC) paradigm. In this paper, we present a study that empirically evaluates the ability of ABC4GSD in supporting teams cooperation. We designed and executed a study based on a scenario that simulated the follow-the-Sun (FTS) strategy of global SE (GSE). Our research design allowed us to ensure cooperation to be both computer-mediated as well as contained within observable short time-windows - the hand-off activities of the FTS strategy. [Results] Overall, the results show that the cooperation support provided by the ABC4GSD system has been positively perceived by the participants. Nonetheless, open issues stimulating further investigations have been raised especially due to a few mixed results. Aware of the limitations of the simulated scenario, we conclude that the approach followed by the ABC4GSD system based on activities is desirable to improve the cooperation support in SE. Finally, our research approach based on simulating a scenario with geographical and temporal distribution can provide useful ideas for assessing collaborative technologies in SE.",2016,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7577417,"Paula G. Mian, Guilherme H. Travassos and Ana Regina C. da Rocha",2nd Experimental Software Engineering Latin American Workshop ? ESELAW?05,0
A Concept-Based Framework for Retrieving Evidence to Support Emergency Physician Decision Making at the Point of Care,"<p>The goal of evidence-based medicine is to uniformly apply evidence gained from scientific research to aspects of clinical practice. In order to achieve this goal, new applications that integrate increasingly disparate health care information resources are required. Access to and provision of evidence must be seamlessly integrated with existing clinical workflow and evidence should be made available where it is most often required - at the point of care. In this paper we address these requirements and outline a concept-based framework that captures the context of a current patient-physician encounter by combining disease and patient-specific information into a logical query mechanism for retrieving relevant evidence from the Cochrane Library. Returned documents are organized by automatically extracting concepts from the evidence-based query to create meaningful clusters of documents which are presented in a manner appropriate for point of care support. The framework is currently being implemented as a prototype software agent that operates within the larger context of a multi-agent application for supporting workflow management of emergency pediatric asthma exacerbations.</p>",2007,http://dl.acm.org/citation.cfm?id=1793667&CFID=932217831&CFTOKEN=19390991,"Dympna O?Sullivan, Ken Farion, Stan Matwin, Wojtek Michalowski and Szymon Wilk","Book Series Lecture Notes in Computer Science,Volume 4924/2008, Book Knowledge Management for Health Care Procedures, Pages 117-126, SpringerLink Date Saturday, February 23, 2008",0
A content based retrieval system for renal scintigraphy images,"Increasing amount of image data raises the importance of content based query systems. Increasing hardware capacity and improving methods makes development of such systems more feasible. In this study, we aim to develop a content based image retrieval for renal (kidney) scintigraphy images. For this purpose, problem analysis, literature survey, data gathering/processing studies are done, and a content-based image retrieval (CBIR) engine software prototype is developed",2006,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1659919,"Nar, F.a , Mumcuog?lu, E.a , Koc?ak, U.a , Ug?ur, O?.b , Bozkurt, F.b , Aslan, M.b , Gu?nes?tepe, K.a , Cerrahog?lu, M.a","(2006) 2006 IEEE 14th Signal Processing and Communications Applications Conference, 2006, art. no. 1659919, .",0
A Cost-Effective Usability Evaluation Progression for Novel Interactive Systems,"This paper reports on user interface design and evaluation for a mobile, outdoor, augmented reality (AR) application. This novel system, called the battlefield augmented reality system (BARS), supports information presentation and entry for situation awareness in an urban war fighting setting. To our knowledge, this is the first time extensive use of usability engineering has been systematically applied to development of a real-world AR system. Our BARS team has applied a cost-effective progression of usability engineering activities from the very beginning of BARS development. We discuss how we first applied cycles of structured expert evaluations to BARS user interface development, employing user interface mockups representing occluded (non-visible) objects. Then we discuss how results of these evaluations informed our subsequent user-based statistical evaluations and formative evaluations, and present these evaluations and their outcomes. Finally, we discuss how and why this sequence of types of evaluation is cost-effective.",2004,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=1265653,"By Deborah Hix , Joseph L. Gabbard , J. Edward Swan II , Mark A. Livingston , Tobias H. Hollerer , Simon J. Julier , Yohan Baillot , Dennis Brown","Found in: Proceedings of the 37th Annual Hawaii International Conference on System Sciences (HICSS'04) - Track 9
Issue Date:January 2004 , pp. 90276c",0
A Critical Analysis of the Council of Europe Recommendations on e-voting,"<p>In September 2004, the Council of Europe's Committee of Ministers officially adopted a set of standards recommended by the Multidisciplinary Ad Hoc Group of Specialists on legal, operational and technical standards for e-enabled voting [7].</p> <p>This paper puts the standards in their historical context, examines them according to established software engineering principles, and finally suggests how they could be restructured.</p>",2006,http://dl.acm.org/citation.cfm?id=1251012&CFID=932213982&CFTOKEN=88044337,Margaret McGaley and J. Paul Gibson,"Proceedings of the USENIX/Accurate Electronic Voting Technology Workshop 2006 on Electronic Voting Technology Workshop, Vancouver, B.C., Canada, Pages: 9 ? 9, Year of Publication: 2006",0
A Critical Approach to Privacy Research in Ubiquitous Environments ? Issues and Underlying Assumptions,"<p>This paper explores the different aspects of ubiquitous environments with regard to the protection of individuals' private life. A critical review of the relative research reveals two major trends. First, that there is a shift in the perception of privacy protection, which is increasingly considered as a responsibility of the individual, instead of an individual right protected by a central authority, such as a state and its laws. Second, it appears that current IT research is largely based on the assumption that personal privacy is quantifiable and bargainable. This paper discusses the impact of these trends and underlines the issues and challenges that emerge. The paper stresses that, for the time being, IT research approaches privacy in ubiquitous environments without taking into account the different aspects and the basic principles of privacy. Finally the paper stresses the need for multidisciplinary research in the area, and the importance that IT research receives input from other related disciplines such as law and psychology. The aim of the paper is to contribute to the ongoing discourse about the nature of privacy and its role in ubiquitous environments and provide insights for future research.</p>",2007,http://dl.acm.org/citation.cfm?id=1780831&CFID=932219082&CFTOKEN=62315287,"Maria Karyda, Stefanos Gritzalis and Jong Hyuk Park","Book Series Lecture Notes in Computer Science, Volume 4809/2007, Book Emerging Directions in Embedded and Ubiquitous Computing, Pages 12-21, SpringerLink Date Tuesday, November 27, 2007",0
A Cross-Cultural Study of Flow Experience in the IT Environment: The Beginning,"<p>Flow (optimal) experience is being widely investigated in the IT environments: in human-computer interaction, computer-mediated communication and exploratory behaviour, consumer and marketing applications, educational practice, playing computer, video and online games, psychological rehabilitation of the disabled, web usability testing, etc. Though a universal experience, flow can be expected to be culture specific and culture dependent. Optimal experience has only rarely been studied from a cross-cultural perspective, mainly in the field of gaming activities. An overview of the earliest works in the field is presented, as well as empirical evidences of a study referring to the flow experience and interaction patterns inherent to the samples of Russian and French online players.</p>",2007,http://dl.acm.org/citation.cfm?id=1784321&CFID=932213054&CFTOKEN=98968856,Alexander E. Voiskounsky,"Book Series Lecture Notes in Computer Science, Volume 4564/2007, Book Online Communities and Social Computing, Pages 202-211, SpringerLink Date Friday, August 24, 2007",0
A Cross-Lingual Framework for Web News Taxonomy Integration,"<p>There are currently many news sites providing online news articles, and many Web news portals arise to provide clustered news categories for users to browse more related news reports and realize the news events in depth. However, to the best of our knowledge, most Web news portals only provide monolingual news clustering services. In this paper, we study the cross-lingual Web news taxonomy integration problem in which news articles of the same news event reported in different languages are to be integrated into one category. Our study is based on cross-lingual classification research results and the cross-training concept to construct SVM-based classifiers for cross-lingual Web news taxonomy integration. We have conducted several experiments with the news articles from Google News as the experimental data sets. From the experimental results, we find that the proposed cross-training classifiers outperforms the traditional SVM classifiers in an all-round manner. We believe that the proposed framework can be applied to different bilingual environments.</p>",2006,http://dl.acm.org/citation.cfm?id=2111263&CFID=932218719&CFTOKEN=56773150,"Cheng-Zen Yang, Che-Min Chen and Ing-Xiang Chen","Book Series Lecture Notes in Computer Science, Volume 4182/2006, Book Information Retrieval Technology, Pages 270-283, SpringerLink Date Wednesday, October 18, 2006",0
A curriculum for embedded system engineering,"This paper describes an educational achievement in embedded system field from the academic year 2010 to 2011 in a national college of technology called &#x201C;KOSEN.&#x201D; We the authors have been continuing specialized education in the field of the embedded system in order to let students be work-ready engineers in various industrial fields. However, it is recently getting harder and harder for students to imagine their future vision as engineers and to excite their spontaneous motivation to learn. One reason is the fact that it is difficult for students to imagine relationship between final embedded-products and elementary contents of lectures that they study in the college. Furthermore, recent embedded systems are too complex to put the whole picture together. To cope with these problems, we have achieved the following four activities for improvement of our curriculum: 1) Maturing educational partnership with local schools through open-lectures to provide early education to pupils who will be our students in future; 2) Developing a multiplicity-carrying microprocessor board as a new teaching material with its online manual and software libraries; 3) Carrying out several special lectures and meetings which are held for various stages of students in order to provide opportunities for them to become interested in the actual industrial fields; 4) Incorporating a lecture on model-based embedded-product design for advanced course students. Through these activities for improvement of our curriculum, we had provided diverse opportunities to students. We verified the effectiveness of our activities by using questionnaires, and then more than 80% of students affirmed the effectiveness.",2012,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6360376,Rudolph E. Seviora,ACM Transactions on Embedded Computing Systems (2005),0
A Data Integration Broker for Healthcare Systems,"A prototype information broker uses a software service model to collect and integrate diverse patient data from autonomous healthcare agencies, potentially solving many problems that challenge current enterprise-based file systems",2007,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4160220,"By David Budgen , Michael Rigby , Pearl Brereton , Mark Turner","Computer 
Issue Date:April 2007 
pp. 34-41",0
A DEFECT PREDICTION METHOD FOR SOFTWARE VERSION DIFFERENCES,"One of the challenges in any software organization is the prediction of acceptable degree of software. The effort invested in a software project in terms of required hours of work against required number of people for a project is probably one of the most important and most analysed variables in recent years in the process of prediction of project success. Thus, effort estimation with a high grade of reliability remains as one of the risky components where in the project manager has to deal with it since the inception of project development. Over the past decades hence, prediction of product quality within software engineering, preventive and corrective actions within the various project phases are constantly improved. This paper therefore introduces a novel hybrid method of random forest (RF) and Fuzzy C Means (FCM) clustering for building defect prediction model. Initially, random forest algorithm is used to perform a preliminary screening of variables and to gain an importance ranks. Subsequently, the new dataset is input into the FCM technique, which is responsible for building interpretable models for predicting defects. The capability of this combination method is evaluated using basic performance measurements along with a 10-fold cross validation. FCM and RF technique is applied to software components such as people, process, which act as major decision making model for project success. Experimental results show that the proposed method provides a higher accuracy and a relatively simple model enabling a better prediction of software defects.",2014,http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=6892743,Yomi Kastro,"Submitted to the Institute for Graduate Studies in Science and Engineering in partial fulfillment of the requirements for the degree of Master of Science, Graduate Program in Computer Engineering, Bogazi?i University, 2006",0
